{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7edd72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from filegenerators import *\n",
    "from typing import Dict, List, Union, Optional\n",
    "pd.options.display.float_format = '{:.2e}'.format\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from CovCor_calc import OptimaMechtest, OptimaOutput, OptimaSensitivity\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "from scipy.linalg import sqrtm, logm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7239c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theoretical_Ranges:\n",
    "    def __init__(self, range_file: str, sheet_name: str, input_names: list[str],\n",
    "                 must_be_zero: list[str]) -> None:\n",
    "        \n",
    "        self.df_species_ics = pd.read_excel(range_file, sheet_name=sheet_name)\n",
    "        self.df_species_ics['value'] = self.df_species_ics['value'].astype(float)\n",
    "        self.must_be_zero = must_be_zero\n",
    "        self.get_input_data(input_names)\n",
    "        self.gen_lookuptable()\n",
    "\n",
    "    def get_input_data(self, input_names: list[str]) -> None:\n",
    "        self.inputs = {}\n",
    "        for i in input_names:\n",
    "            self.inputs[i] = 0.0\n",
    "        self.inputs[\"REF\"] = 1.0\n",
    "        self.inputs[\"Insulin\"] = 1e-10\n",
    "\n",
    "        self.input_data = pd.DataFrame([\n",
    "            {'species': species, 'minconc': value, 'value': value, 'maxconc': value}\n",
    "            for species, value in self.inputs.items()])\n",
    "\n",
    "    def gen_lookuptable(self) -> None:\n",
    "        self.lut = pd.concat([self.df_species_ics, self.input_data], ignore_index=True)    # look-up-table\n",
    "        self.lut['species'] = self.lut['species'].str.upper()\n",
    "        print(f\"LUT was created successfully. Its dimensions are: {self.lut.shape}\")\n",
    "\n",
    "    def makeBounds(self, old = True):\n",
    "        bounds = dict()\n",
    "        for index, row in self.df_species_ics.iterrows():\n",
    "            if row.value < 0.1:\n",
    "                lb = 1e-14\n",
    "                ub = 1e-13\n",
    "            elif old:\n",
    "                lb = (row.value/2)*1e-12\n",
    "                ub = (row.value*1.5)*1e-12\n",
    "            else:\n",
    "                lb = (row.minconc)*1e-12\n",
    "                ub = (row.maxconc)*1e-12\n",
    "            bounds[row.species] = [lb, ub]\n",
    "        return bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadbb764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basal:\n",
    "    def __init__(self, rng: Theoretical_Ranges, sampling_type: str, wide = False) -> None:\n",
    "        self.rng = rng\n",
    "        self.wide = wide\n",
    "        self.old = self.get_sampling_type(sampling_type)   # Should be 'old' or 'new'\n",
    "        self.bounds = self.rng.makeBounds(self.old)\n",
    "        self.get_observables()\n",
    "        self.rel_sigmas = self.get_sigma_dict()\n",
    "        self.get_dataPoints()\n",
    "\n",
    "    def get_sampling_type(self, sampling_type: str) -> bool:\n",
    "        if sampling_type == 'old':\n",
    "            if self.wide == True:\n",
    "                raise ValueError(\"If the sampling type is 'old', wide needs to be False.\")\n",
    "            else:\n",
    "                self.sampling_type = 'old'\n",
    "                return True\n",
    "        elif sampling_type == 'new':\n",
    "            if self.wide:\n",
    "                self.sampling_type = 'wide_new'\n",
    "            else:\n",
    "                self.sampling_type = 'new'\n",
    "            return False\n",
    "        else:\n",
    "            raise ValueError(\"The sampling type can either be 'old' or 'new'.\")\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        kiir = f\"Fields:\\ndim(bounds): {len(self.bounds)}\\n\" + \\\n",
    "               f\"dim(observables): {len(self.observables)}\\n\" + \\\n",
    "               f\"dim(sigma_dict): {len(self.rel_sigmas)}\\n\" + \\\n",
    "               f\"dim(dataPoints): {self.dataPoints.shape}\"\n",
    "        return kiir\n",
    "\n",
    "    def get_observables(self) -> None:\n",
    "        self.observables = []\n",
    "        for index, row in self.rng.df_species_ics.iterrows():\n",
    "            if row.value > 0:\n",
    "                self.observables.append(row.species)\n",
    "\n",
    "    def get_sigma_dict(self) -> dict[str, float]:\n",
    "        rel_sigmas = dict()\n",
    "\n",
    "        for index, row in self.rng.df_species_ics.iterrows():\n",
    "            if row.species in self.rng.inputs.keys():\n",
    "                # if row.species not in observables:\n",
    "                continue\n",
    "            if row.value in self.rng.must_be_zero and row.species not in self.rng.inputs.keys():\n",
    "                rel_sigmas[row.species] = 5e-14\n",
    "            elif row.species not in self.rng.inputs.keys() and row.species in self.observables:\n",
    "                if self.wide and row.minconc != row.maxconc:\n",
    "                    rel_sigmas[row.species] = ((row.maxconc-row.minconc)/8)*1e-12\n",
    "                else:\n",
    "                    rel_sigmas[row.species] = ((row.value*1.5-row.value/2)/8)*1e-12\n",
    "        return rel_sigmas\n",
    "\n",
    "    def get_dataPoints(self) -> None:\n",
    "        columns = list(set(self.observables)-set(self.rng.inputs.keys()))\n",
    "        columns.sort()\n",
    "        columns.insert(0,'time')\n",
    "        time = np.linspace(0,24,25)\n",
    "\n",
    "        self.dataPoints = pd.DataFrame(columns=columns)\n",
    "        self.dataPoints['time'] = time*60\n",
    "\n",
    "        # Fill in the \"theoretical\" stationary conentrations\n",
    "        for index, row in self.rng.df_species_ics.iterrows():\n",
    "            if row.species in self.dataPoints.columns:\n",
    "                if row.value == 0:\n",
    "                    self.dataPoints.loc[:,row.species] = 1e-13\n",
    "                else:\n",
    "                    self.dataPoints.loc[:,row.species] = row.value*1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e0c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genesis:  # As in it creates the xmls ~ the cells {= life ;)} with different initial conditions\n",
    "    def __init__(self, basal: Basal, num_of_xmls: int,\n",
    "                 output_directory: str = '/home/nvme/Opt/7_Krisztian/xml/') -> None:\n",
    "        self.basal = basal\n",
    "        self.num_xmls = num_of_xmls\n",
    "        self.maxdigit = len(str(num_of_xmls))\n",
    "        self.check_output_dir(output_directory)\n",
    "        self.let_there_be_life()\n",
    "\n",
    "    def check_output_dir(self, output_directory) -> None:\n",
    "        if self.basal.old and not self.basal.wide:\n",
    "            folder_name = f\"Basal_{self.num_xmls}_old\"\n",
    "        elif not self.basal.old and not self.basal.wide:\n",
    "            folder_name = f\"Basal_{self.num_xmls}_new\"\n",
    "        else:\n",
    "            folder_name = f\"Basal_{self.num_xmls}_wide_new\"\n",
    "\n",
    "        self.output_dir = os.path.join(output_directory, folder_name)\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            print(f\"No existing directory was found at {self.output_dir}. Creating one now...\")\n",
    "\n",
    "    def let_there_be_life(self) -> None:\n",
    "        species = self.basal.rng.df_species_ics.species.to_list()\n",
    "        inputs = self.basal.rng.inputs\n",
    "        input_names = inputs.keys()\n",
    "        only_vars = list(set(species)-set(input_names))\n",
    "\n",
    "        for i in range(1, self.num_xmls+1):\n",
    "            file_index = i\n",
    "            generate_file(file_index, self.output_dir, only_vars, inputs,\n",
    "                          self.basal.bounds, self.basal.dataPoints,\n",
    "                          self.basal.rel_sigmas, self.maxdigit)\n",
    "\n",
    "        print(\"job finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a9d1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, gen: Genesis, xmls_in_one_opp: int, opp_output_dir: str,\n",
    "                 opp_name_prefix: str, all_in_one=False, kiir=True) -> None:\n",
    "        self.gen = gen\n",
    "        self.all_in_one = all_in_one\n",
    "        self.get_xml_vec(xmls_in_one_opp)\n",
    "        self.opp(opp_output_dir, opp_name_prefix, kiir)\n",
    "\n",
    "    def get_xml_vec(self, xmls_in_one_opp) -> None:\n",
    "        if self.all_in_one:\n",
    "          self.xmls = np.arange(1, self.gen.num_xmls + 1, 1)\n",
    "        else:\n",
    "          self.xmls = []\n",
    "          for i in range(1, self.gen.num_xmls, xmls_in_one_opp):\n",
    "            xml_cnt = np.arange(i, i+xmls_in_one_opp, 1) \n",
    "            self.xmls.append(xml_cnt)\n",
    "\n",
    "    def opp(self, opp_output_dir, opp_name_prefix, kiir) -> None:\n",
    "        self.opps = []\n",
    "        self.indices = []\n",
    "        if self.all_in_one:\n",
    "          opp_content = self.generate_opp_content(self.gen.output_dir, name='stac', num_xmls=self.xmls)\n",
    "          opp_filename = f\"{opp_name_prefix}_BCRN_corr_{self.xmls[-1]}_{self.gen.basal.sampling_type}.opp\"\n",
    "          self.opps.append(opp_filename)\n",
    "          self.indices.append(f\"{self.xmls[-1]}\")\n",
    "          if kiir:\n",
    "            with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "              f.write(opp_content)\n",
    "        else:\n",
    "          for num in self.xmls:\n",
    "              opp_content = self.generate_opp_content(self.gen.output_dir, name='stac', num_xmls=num)\n",
    "              opp_filename = f\"{opp_name_prefix}_BCRN_corr_{num[-1]}_{self.gen.basal.sampling_type}.opp\"\n",
    "              self.opps.append(opp_filename)\n",
    "              self.indices.append(f\"{num[-1]}\")\n",
    "              if kiir:\n",
    "                with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "                  f.write(opp_content)\n",
    "\n",
    "    def generate_opp_content(self, xml_folder: str, num_xmls: Union[list[int], list[list[int]]], mech_file: str = \"7_Krisztian/mech/BCRN6.inp\", \n",
    "                            name: str = 'stac', yaml_file: str = \"7_Krisztian/mech/BCRN6.yaml\", time_limit: int = 50, thread_limit: int = 32,\n",
    "                            settings_tag: str = \"systems_biology\", solver: str = \"cantera\", extension: str = \".xml\") -> str:\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         BCRN6\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_cantera  {yaml_file}\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  BCRN6\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml in num_xmls:\n",
    "          padded_number = str(xml).zfill(self.gen.maxdigit)\n",
    "          mechtest += f\"      NAME {xml_folder}/{name}_{padded_number}.xml\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    def sim_runner(self, log_location:str = ''):\n",
    "      self.parent_path = parent_path = Path.cwd().parents[1]\n",
    "        \n",
    "      if log_location == '':\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "            command = [\"bin/Release/OptimaPP\", f\"7_Krisztian/1_mechtest/{opp_file}\"]\n",
    "            print(f\"Running: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, cwd=parent_path)\n",
    "      else:\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "          command = [\"bin/Release/OptimaPP\", f\"7_Krisztian/1_mechtest/{opp_file}\"]\n",
    "          print(f\"Running: {' '.join(command)}\")\n",
    "          if self.all_in_one:\n",
    "             log_idx = self.xmls[-1]\n",
    "          else:\n",
    "             log_idx = self.xmls[idx][-1]\n",
    "          with open(f\"../logs/2025526/run_log_old{log_idx}.txt\", \"w\") as log:\n",
    "              subprocess.run(command, check=True, stdout=log, stderr=subprocess.STDOUT, cwd=parent_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6114ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Natural_Selection:\n",
    "    def __init__(self, sim: Simulation) -> None:\n",
    "        self.sim = sim\n",
    "        self.sim_data: dict[str, OptimaMechtest] = {}\n",
    "        self.get_sim_data()\n",
    "        self.survival_of_the_fittest()\n",
    "\n",
    "    def get_sim_data(self) -> None:\n",
    "        for idx, key in enumerate(self.sim.indices):\n",
    "            self.sim_data[key] = OptimaMechtest(self.sim.opps[idx])\n",
    "\n",
    "    def sigma_range(self, meas, sim, sigma):\n",
    "        radius = (sim-meas)/sigma\n",
    "        return radius\n",
    "    \n",
    "    def isit_init(self, row, wide=False):\n",
    "        lut = self.sim.gen.basal.rng.lut\n",
    "        rel_sigmas = self.sim.gen.basal.rel_sigmas\n",
    "        for k, v in row.items():\n",
    "            right_row = lut[lut['species'] == k]\n",
    "\n",
    "            if right_row.empty or k not in rel_sigmas.keys():\n",
    "                #print(f\"Species '{species}' not found in lut â€” skipping.\")\n",
    "                continue    # ezekre: BEC1A, PI3K, PI3KA, SERCAA nincsen adat a ranges tablazatban\n",
    "\n",
    "            meas = right_row['value'].iloc[0] * 1e-12\n",
    "\n",
    "            if not wide:\n",
    "                radius = self.sigma_range(meas=meas, sim=v*1e-12, sigma=rel_sigmas[k])\n",
    "            else:\n",
    "                radius = self.sigma_range(meas=meas, sim=v*1e-12, sigma=rel_sigmas[k])\n",
    "\n",
    "            if radius >= 4:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def survival_of_the_fittest(self) -> None:\n",
    "        self.good_xmls = []\n",
    "        for idx in self.sim.indices:\n",
    "            for xml_name, row in self.sim_data[idx].df_followed34.iterrows():\n",
    "                all_ok = self.isit_init(row)\n",
    "                if all_ok:\n",
    "                    self.good_xmls.append(xml_name)\n",
    "        print(f\"Found {len(self.good_xmls)} good xmls\")\n",
    "\n",
    "    def filtering(self) -> None:\n",
    "        data = copy.deepcopy(self.sim_data)\n",
    "        first = True\n",
    "        self.filtered_basal = pd.DataFrame()\n",
    "        self.filtered_followed = pd.DataFrame()\n",
    "        for k, v in data.items():\n",
    "            v.df_basal.index = v.df_basal.index.str[7:-9]\n",
    "            v.df_basal = v.df_basal.sort_index()\n",
    "            if first:\n",
    "                self.filtered_basal = v.df_basal[[xml in self.good_xmls for xml in v.df_basal.index]]\n",
    "                self.filtered_followed = v.df_followed34[[xml in self.good_xmls for xml in v.df_followed34.index]]\n",
    "                first = False\n",
    "            else:\n",
    "                self.filtered_basal = pd.concat([self.filtered_basal, v.df_basal[[xml in self.good_xmls for xml in v.df_basal.index]]],\n",
    "                                        ignore_index=False)\n",
    "                self.filtered_followed = pd.concat([self.filtered_followed, v.df_followed34[[xml in self.good_xmls for xml in v.df_followed34.index]]],\n",
    "                                            ignore_index=False)\n",
    "\n",
    "    def get_cov_cor(self, corr_xmls, keys: list[str]) -> None:\n",
    "        self.dict_b = {}\n",
    "        self.dict_f = {}\n",
    "        self.dict_b_corr = {}\n",
    "        self.dict_f_corr = {}\n",
    "        self.dict_b_cov = {}\n",
    "        self.dict_f_cov = {}\n",
    "        for idx, range in enumerate(corr_xmls):\n",
    "            self.dict_f[f\"{keys[idx]}\"] = self.filtered_followed.iloc[range].copy()\n",
    "            self.dict_b[f\"{keys[idx]}\"] = self.filtered_basal.iloc[range].copy()\n",
    "            self.dict_b_corr[f\"{keys[idx]}\"] = self.filtered_basal.iloc[range].copy().corr()\n",
    "            self.dict_f_corr[f\"{keys[idx]}\"] = self.filtered_followed.iloc[range].copy().corr()\n",
    "            self.dict_f_cov[f\"{keys[idx]}\"] = self.filtered_followed.iloc[range].copy().cov()\n",
    "            self.dict_b_cov[f\"{keys[idx]}\"] = self.filtered_basal.iloc[range].copy().cov()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975724a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alma\n",
      "korte\n",
      "meggy\n",
      "eper\n",
      "szilva\n"
     ]
    }
   ],
   "source": [
    "gyumik = {'alma': 'finom', 'korte': 'nem rossz', 'meggy': 'nyami', 'eper': 'nyami', 'szilva': 'nyami'}\n",
    "for i in gyumik.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce50f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUT was created successfully. Its dimensions are: (84, 4)\n",
      "job finished\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    input_names = ['nS', 'RAP', 'TG', 'dS', 'CCH', 'REF', 'Insulin', 'TG_SERCA', 'mTOR_RAP', 'casp', 'IP3R', 'Baxa', 'tBid']\n",
    "    must_be_zero = ['casp', 'Baxa', 'tBid', 'p53a', 'PUMA']\n",
    "    \n",
    "    rng = Theoretical_Ranges('input_files/reactions_ics_finalised.xlsx', 'icranges',\n",
    "                               input_names, must_be_zero)\n",
    "\n",
    "    basal = Basal(rng, 'old')\n",
    "\n",
    "    gen = Genesis(basal, 50)\n",
    "\n",
    "    sim = Simulation(gen, 10, '../1_mechtest', 'ezaz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481c80d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.num_xmls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
