{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f010f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jinja2\n",
    "import bibtexparser\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc411521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Core Classes (same logic)\n",
    "# ----------------------------\n",
    "\n",
    "class Experiment:\n",
    "    def __init__(self, data_source,  # str path or pd.DataFrame\n",
    "                 stresses: dict[str, tuple[float, str]],\n",
    "                 bibtex: str = \"\"):\n",
    "\n",
    "        if isinstance(data_source, str):\n",
    "            self.name = os.path.splitext(os.path.basename(data_source))[0]\n",
    "            self.experiment_data = pd.read_csv(data_source)\n",
    "        elif isinstance(data_source, pd.DataFrame):\n",
    "            self.name = \"worksheet_experiment\"\n",
    "            self.experiment_data = data_source.copy()\n",
    "        else:\n",
    "            raise ValueError(\"data_source must be a file path or a pandas DataFrame\")\n",
    "\n",
    "        self.stresses = stresses\n",
    "        self.bibtex = self.parse_bibtex(bibtex)\n",
    "        self.non_species_cols = {\"TIME\"}\n",
    "        self.process_data()\n",
    "\n",
    "    def parse_bibtex(self, bibtex_str):\n",
    "        parser = bibtexparser.loads(bibtex_str)\n",
    "        if not parser.entries:\n",
    "            raise ValueError(\"BibTeX parse produced no entries.\")\n",
    "        entry = parser.entries[0]\n",
    "\n",
    "        return {\n",
    "            \"author\": entry.get(\"author\", \"\"),\n",
    "            \"title\": entry.get(\"title\", \"\"),\n",
    "            \"journal\": entry.get(\"journal\", \"\"),\n",
    "            \"volume\": entry.get(\"volume\", \"\"),\n",
    "            \"number\": entry.get(\"number\", \"\"),\n",
    "            \"year\": entry.get(\"year\", \"\"),\n",
    "            \"doi\": entry.get(\"doi\", entry.get(\"url\", \"\")),\n",
    "        }\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        self.experiment_data.columns = [col.upper() for col in self.experiment_data.columns]\n",
    "        # keep your behavior:\n",
    "        self.experiment_data.rename(columns={'TIME': 'time'}, inplace=True)\n",
    "        self.experiment_data = self.experiment_data.dropna()\n",
    "        self.species = [\n",
    "            v for v in self.experiment_data.columns\n",
    "            if v.upper() not in self.non_species_cols and \"STD\" not in v.upper()\n",
    "        ]\n",
    "\n",
    "    def quantitated_exp_data(self, ics: dict[str, float]) -> None:\n",
    "        quant_Data = self.experiment_data.copy()\n",
    "        species_and_std = [col for col in quant_Data.columns if col.upper() not in self.non_species_cols]\n",
    "        for s in species_and_std:\n",
    "            if 'STD' in s.upper():\n",
    "                quant_Data[s] *= ics[s[0:-3]]\n",
    "            else:\n",
    "                quant_Data[s] *= ics[s]\n",
    "        self.quant_data = quant_Data\n",
    "\n",
    "\n",
    "class TheoreticalRanges:\n",
    "    def __init__(self, min_max_path: str, scaling_factor: float, first_species_col: int):\n",
    "        self.name = os.path.splitext(os.path.basename(min_max_path))[0]\n",
    "        if min_max_path.endswith('.csv'):\n",
    "            self.df_ranges = pd.read_csv(min_max_path)\n",
    "        elif min_max_path.endswith('.xlsx'):\n",
    "            self.df_ranges = pd.read_excel(min_max_path, sheet_name=\"icranges\")\n",
    "        else:\n",
    "            raise ValueError(\"Range file must be .csv or .xlsx\")\n",
    "\n",
    "        self.scaling_factor = float(scaling_factor)\n",
    "        self.df_scaled_ranges = self.df_ranges.select_dtypes(include='number') * self.scaling_factor\n",
    "        self.bounds = self.get_bounds()\n",
    "\n",
    "    def get_bounds(self) -> dict[str, tuple[float, float]]:\n",
    "        bounds = {}\n",
    "        for idx, row in self.df_ranges.iterrows():\n",
    "            lb = row['minconc'] * self.scaling_factor\n",
    "            ub = row['maxconc'] * self.scaling_factor\n",
    "            if pd.isna(lb) or lb < 0:\n",
    "                lb = 0.0\n",
    "            if pd.isna(ub) or ub < 0:\n",
    "                ub = 0.0\n",
    "            bounds[row['species']] = [float(lb), float(ub)]\n",
    "        return bounds\n",
    "\n",
    "    def check_compatibility(self, experiment: Experiment) -> None:\n",
    "        for s in experiment.species:\n",
    "            if s not in self.bounds:\n",
    "                self.bounds[s] = [0.0, 0.0]\n",
    "\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, species_range: TheoreticalRanges, experiment: Experiment):\n",
    "        self.species_range = species_range\n",
    "        self.experiment = experiment\n",
    "        self.species_range.check_compatibility(experiment=self.experiment)\n",
    "\n",
    "    def create_xml_files(self, output_xmls_path: str, num_of_xmls: int, xml_template_path: str) -> None:\n",
    "        os.makedirs(output_xmls_path, exist_ok=True)\n",
    "\n",
    "        env = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(xml_template_path)))\n",
    "        self.template = env.get_template(os.path.basename(xml_template_path))\n",
    "\n",
    "        for i in range(1, num_of_xmls + 1):\n",
    "            self.random_ics = self.get_random_ics()\n",
    "            self.experiment.quantitated_exp_data(ics=self.random_ics)\n",
    "            self.make_xml_output(i, output_xmls_path)\n",
    "\n",
    "    def get_random_ics(self) -> dict[str, float]:\n",
    "        random_ics = {s: np.random.uniform(*self.species_range.bounds[s]) for s in self.species_range.bounds}\n",
    "\n",
    "        # keep your override behavior:\n",
    "        for s in self.experiment.stresses:\n",
    "            if self.experiment.stresses[s][1] == \"molecular_species\":\n",
    "                random_ics[s] = self.experiment.stresses[s][0]\n",
    "\n",
    "        random_ics[\"REF\"] = 1.0\n",
    "        return random_ics\n",
    "\n",
    "    def make_xml_output(self, file_index: int, output_xmls_path: str) -> None:\n",
    "        dataPoints = [self.compileDataRow(row.values) for _, row in self.experiment.quant_data.iterrows()]\n",
    "        output = self.template.render(\n",
    "            ics=self.random_ics,\n",
    "            variables=self.experiment.species,\n",
    "            dataPoints=dataPoints,\n",
    "            bib=self.experiment.bibtex\n",
    "        )\n",
    "\n",
    "        author = (self.experiment.bibtex.get('author') or \"Unknown\").split()\n",
    "        author_tag = (author[0][:-1] if author else \"Unknown\")\n",
    "        year = self.experiment.bibtex.get(\"year\") or \"????\"\n",
    "\n",
    "        filename = f\"{author_tag+'_'+year}_{self.experiment.name}_{file_index:04d}.xml\"\n",
    "        with open(os.path.join(output_xmls_path, filename), 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(output)\n",
    "\n",
    "    def compileDataRow(self, dataPoints):\n",
    "        meas = \"\".join(f\"<{v}>{{:.4e}}</{v}>\" for v in self.experiment.experiment_data.columns)\n",
    "        return f\"<dataPoint>{meas.format(*dataPoints)}</dataPoint>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6514dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NotebookInputs:\n",
    "    experiment_xlsx_path: str                 # Excel with many sheets + last sheet = BibTeX\n",
    "    theoretical_range_path: str               # .csv or .xlsx\n",
    "    scaling_factor: float                     # e.g. 1e-12\n",
    "    first_species_col_index: int              # e.g. 1\n",
    "    xml_template_path: str                    # template .xml\n",
    "    output_xml_dir: str                       # folder for produced xmls\n",
    "    output_opp_dir: str                       # folder for produced .opp\n",
    "    num_xmls_per_sheet: int                   # # of XMLs per worksheet\n",
    "    stress_info: str = \"\"                     # e.g. \"RAP molecular_species 100e-12\" or \"starvation\"\n",
    "    \n",
    "    # .opp defaults (same as your UI method)\n",
    "    mech_file: str = \"7_Krisztian/mech/BCRN6.inp\"\n",
    "    yaml_file: str = \"7_Krisztian/mech/BCRN6.yaml\"\n",
    "    time_limit: int = 50\n",
    "    thread_limit: int = 32\n",
    "    settings_tag: str = \"systems_biology\"\n",
    "    solver: str = \"cantera\"\n",
    "    extension: str = \".xml\"\n",
    "\n",
    "\n",
    "def parse_stress_info(stress_info: str) -> dict[str, tuple[float, str]]:\n",
    "    \"\"\"\n",
    "    Your UI placeholder suggests: \"(molecular_species/starvation RAP 100e-12)\"\n",
    "    But your old parsing was inconsistent and had a bug (it swapped things + mixed types).\n",
    "    \n",
    "    Supported patterns:\n",
    "      1) \"\"  -> {}\n",
    "      2) \"starvation\" -> {\"starvation\": (\"\", \"\")}\n",
    "      3) \"RAP molecular_species 100e-12\" -> {\"RAP\": (1e-10, \"molecular_species\")}\n",
    "         (i.e. <species> <type> <value>)\n",
    "      4) \"molecular_species RAP 100e-12\" -> same, order swapped\n",
    "    \"\"\"\n",
    "    s = (stress_info or \"\").strip()\n",
    "    if not s:\n",
    "        return {}\n",
    "\n",
    "    parts = s.split()\n",
    "    if len(parts) == 1:\n",
    "        # non-molecular stress flag\n",
    "        if parts[0] != \"molecular_species\":\n",
    "            return {parts[0]: (\"\", \"\")}\n",
    "        return {}\n",
    "\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(f\"stress_info must have 0, 1, or 3 tokens, got: {parts}\")\n",
    "\n",
    "    a, b, c = parts[0], parts[1], parts[2]\n",
    "    val = float(c)\n",
    "\n",
    "    # allow either ordering:\n",
    "    if a == \"molecular_species\":\n",
    "        species = b\n",
    "        typ = \"molecular_species\"\n",
    "    elif b == \"molecular_species\":\n",
    "        species = a\n",
    "        typ = \"molecular_species\"\n",
    "    else:\n",
    "        # if you ever want other types, handle here\n",
    "        raise ValueError(\"For 3 tokens, one must be 'molecular_species'.\")\n",
    "\n",
    "    return {species.upper(): (val, typ)}\n",
    "\n",
    "\n",
    "def read_bibtex_from_last_sheet(experiment_xlsx_path: str) -> str:\n",
    "    all_sheets = pd.read_excel(experiment_xlsx_path, sheet_name=None)\n",
    "    last_sheet_name = list(all_sheets.keys())[-1]\n",
    "    bibtex_df = all_sheets[last_sheet_name]\n",
    "\n",
    "    bibtex_lines = bibtex_df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "    bibtex_str = \"\\n\".join([ln for ln in bibtex_lines if ln.strip()])\n",
    "\n",
    "    if not bibtex_str.strip():\n",
    "        raise ValueError(\"No valid BibTeX found in the last worksheet (first column).\")\n",
    "\n",
    "    return bibtex_str\n",
    "\n",
    "\n",
    "def generate_opp_content(\n",
    "    xml_folder: str,\n",
    "    worksheet_name: str,\n",
    "    mech_file: str,\n",
    "    yaml_file: str,\n",
    "    time_limit: int,\n",
    "    thread_limit: int,\n",
    "    settings_tag: str,\n",
    "    solver: str,\n",
    "    extension: str = \".xml\"\n",
    ") -> str:\n",
    "    folder = Path(xml_folder)\n",
    "    xml_files = sorted(f for f in folder.glob(f\"*{worksheet_name}*{extension}\"))\n",
    "\n",
    "    mechmod = f\"\"\"MECHMOD\n",
    "    USE_NAME         BCRN6\n",
    "    MECH_FILE        {mech_file}\n",
    "    COMPILE_cantera  {yaml_file}\n",
    "    END\n",
    "    \"\"\"\n",
    "\n",
    "    mechtest = f\"\"\"MECHTEST\n",
    "        MECHANISM  BCRN6\n",
    "        TIME_LIMIT {time_limit}\n",
    "        THREAD_LIMIT {thread_limit}\n",
    "        SETTINGS_TAG {settings_tag}\n",
    "        FALLBACK_TO_DEFAULT_SETTINGS\n",
    "\n",
    "        SOLVER {solver}\n",
    "        SAVE_STATES      CSV\n",
    "\"\"\"\n",
    "\n",
    "    for xml in xml_files:\n",
    "        mechtest += f\"      NAME {xml.as_posix()}\\n\"\n",
    "\n",
    "    mechtest += \"END\\n\"\n",
    "    return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "\n",
    "def run_simulation_from_notebook(cfg: NotebookInputs, verbose: bool = True):\n",
    "    # Basic sanity checks (helps debugging)\n",
    "    for p in [cfg.experiment_xlsx_path, cfg.theoretical_range_path, cfg.xml_template_path]:\n",
    "        if not os.path.exists(p):\n",
    "            raise FileNotFoundError(p)\n",
    "    os.makedirs(cfg.output_xml_dir, exist_ok=True)\n",
    "    os.makedirs(cfg.output_opp_dir, exist_ok=True)\n",
    "\n",
    "    stresses = parse_stress_info(cfg.stress_info)\n",
    "    bibtex_str = read_bibtex_from_last_sheet(cfg.experiment_xlsx_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== BibTeX read from last sheet ===\")\n",
    "        print(bibtex_str)\n",
    "        print(\"=== Parsed stresses ===\")\n",
    "        print(stresses)\n",
    "\n",
    "    all_sheets = pd.read_excel(cfg.experiment_xlsx_path, sheet_name=None)\n",
    "    sheet_names = list(all_sheets.keys())\n",
    "    data_sheet_names = sheet_names[:-1]  # everything except last (BibTeX)\n",
    "\n",
    "    date = datetime.datetime.now()\n",
    "\n",
    "    produced = {}  # dict[experiment_name -> {\"exp\": Experiment, \"rng\": TheoreticalRanges, \"sim\": Simulation, ...}]\n",
    "\n",
    "    for sheet_name in data_sheet_names:\n",
    "        df = all_sheets[sheet_name]\n",
    "\n",
    "        exp = Experiment(df, stresses, bibtex_str)\n",
    "        exp.name = sheet_name\n",
    "\n",
    "        rng = TheoreticalRanges(cfg.theoretical_range_path, cfg.scaling_factor, cfg.first_species_col_index)\n",
    "        sim = Simulation(rng, exp)\n",
    "\n",
    "        sim.create_xml_files(cfg.output_xml_dir, cfg.num_xmls_per_sheet, cfg.xml_template_path)\n",
    "\n",
    "        opp_content = generate_opp_content(\n",
    "            xml_folder=cfg.output_xml_dir,\n",
    "            worksheet_name=sheet_name,\n",
    "            mech_file=cfg.mech_file,\n",
    "            yaml_file=cfg.yaml_file,\n",
    "            time_limit=cfg.time_limit,\n",
    "            thread_limit=cfg.thread_limit,\n",
    "            settings_tag=cfg.settings_tag,\n",
    "            solver=cfg.solver,\n",
    "            extension=cfg.extension\n",
    "        )\n",
    "\n",
    "        author = (exp.bibtex.get('author') or \"Unknown\").split()\n",
    "        author_tag = (author[0][:-1] if author else \"Unknown\")\n",
    "        opp_filename = f\"{date.year}{date.month:02d}{date.day:02d}_BCRN_{author_tag}_{sheet_name}.opp\"\n",
    "        opp_path = os.path.join(cfg.output_opp_dir, opp_filename)\n",
    "\n",
    "        with open(opp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(opp_content)\n",
    "\n",
    "        # --- store everything under the experiment name (= sheet_name) ---\n",
    "        produced[sheet_name] = {\n",
    "            \"exp\": exp,\n",
    "            \"rng\": rng,\n",
    "            \"sim\": sim,\n",
    "            \"opp_path\": opp_path,\n",
    "            \"opp_filename\": opp_filename,\n",
    "            # optional extras that are often handy for debugging:\n",
    "            # \"stresses\": stresses,\n",
    "            # \"bibtex_str\": bibtex_str,\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[OK] Sheet '{sheet_name}': wrote XMLs to '{cfg.output_xml_dir}', OPP: {opp_path}\")\n",
    "\n",
    "\n",
    "    return produced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5690ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BibTeX read from last sheet ===\n",
      "@article{mattiolo2015autophagy,\n",
      "title={Autophagy exacerbates caspase-dependent apoptotic cell death after short times of starvation},\n",
      "author={Mattiolo, Paolo and Yuste, Victor J and Boix, Jacint and Ribas, Judit},\n",
      "journal={Biochemical Pharmacology},\n",
      "volume={98},\n",
      "number={4},\n",
      "pages={573--586},\n",
      "year={2015},\n",
      "publisher={Elsevier}\n",
      "}\n",
      "=== Parsed stresses ===\n",
      "{'starvation': ('', '')}\n",
      "[OK] Sheet 'Casp': wrote XMLs to '../../../../BCRN/xml', OPP: ../../../../BCRN/1_mechtest\\20260116_BCRN_Mattiolo_Casp.opp\n",
      "[OK] Sheet 'cyt': wrote XMLs to '../../../../BCRN/xml', OPP: ../../../../BCRN/1_mechtest\\20260116_BCRN_Mattiolo_cyt.opp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Casp': {'exp': <__main__.Experiment at 0x1f92f7d8830>,\n",
       "  'rng': <__main__.TheoreticalRanges at 0x1f92f7da660>,\n",
       "  'sim': <__main__.Simulation at 0x1f92f7db770>,\n",
       "  'opp_path': '../../../../BCRN/1_mechtest\\\\20260116_BCRN_Mattiolo_Casp.opp',\n",
       "  'opp_filename': '20260116_BCRN_Mattiolo_Casp.opp'},\n",
       " 'cyt': {'exp': <__main__.Experiment at 0x1f9302ca5d0>,\n",
       "  'rng': <__main__.TheoreticalRanges at 0x1f92fb75090>,\n",
       "  'sim': <__main__.Simulation at 0x1f92ef81590>,\n",
       "  'opp_path': '../../../../BCRN/1_mechtest\\\\20260116_BCRN_Mattiolo_cyt.opp',\n",
       "  'opp_filename': '20260116_BCRN_Mattiolo_cyt.opp'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# EDIT THESE like your UI\n",
    "# ----------------------------\n",
    "cfg = NotebookInputs(\n",
    "    experiment_xlsx_path=\"../../../../BCRN/0_evaluate/input_files/Mattiolo_2015.xlsx\",\n",
    "    theoretical_range_path=\"../../../../BCRN/0_evaluate/input_files/reactions_ics_finalised_tester.xlsx\",        # or .xlsx\n",
    "    scaling_factor=1e-12,\n",
    "    first_species_col_index=1,\n",
    "    xml_template_path=\"../../../../BCRN/0_evaluate/input_files/xml_template.xml\",\n",
    "    output_xml_dir=\"../../../../BCRN/xml\",\n",
    "    output_opp_dir=\"../../../../BCRN/1_mechtest\",\n",
    "    num_xmls_per_sheet=1,\n",
    "    stress_info=\"starvation\",         # or \"starvation\" or \"\"\n",
    ")\n",
    "\n",
    "produced = run_simulation_from_notebook(cfg, verbose=True)\n",
    "produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f87f221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>CASP</th>\n",
       "      <th>CASPSTD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  CASP  CASPSTD\n",
       "0     0   0.0      0.0\n",
       "1     3   0.0      0.0\n",
       "2     6   0.0      0.0\n",
       "3     9   0.0      0.0\n",
       "4    12   0.0      0.0\n",
       "5    16   0.0      0.0\n",
       "6    24   0.0      0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produced['Casp']['exp'].quant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d30acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\Users\\local_user\\Desktop\\Study\\VII_semester\\TDK\\BCRN\\0_evaluate\\codes\\others\n"
     ]
    }
   ],
   "source": [
    "curr = os.getcwd()\n",
    "print(f\"Current working directory: {curr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
