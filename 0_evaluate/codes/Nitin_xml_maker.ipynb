{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dad775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from filegenerators import *\n",
    "pd.options.display.float_format = '{:.2e}'.format\n",
    "import os\n",
    "import bibtexparser\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50066ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theoretical_Ranges:\n",
    "    def __init__(self, min_max_path: str, input_names: list[str], must_be_zero: list[str],\n",
    "                 scaling_factor: float=1e-12, sheet_name:str = 'icranges'):\n",
    "        self.name = os.path.splitext(os.path.basename(min_max_path))[0]\n",
    "        self.df_ranges = pd.read_excel(min_max_path, sheet_name=sheet_name)\n",
    "        self.df_ranges['value'] = self.df_ranges['value'].astype(float)\n",
    "        self.df_ranges.species = [s.upper() for s in self.df_ranges.species]\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.df_scaled_ranges = self.df_ranges.select_dtypes(include='number') * self.scaling_factor\n",
    "        self.must_be_zero = must_be_zero\n",
    "        self.input_names = input_names\n",
    "        self.get_input_data(input_names)\n",
    "        self.bounds = self.get_bounds()\n",
    "        self.gen_lookuptable()\n",
    "\n",
    "    def get_input_data(self, input_names: list[str]) -> None:\n",
    "        self.inputs = {}\n",
    "        for i in input_names:\n",
    "            self.inputs[i] = 0.0\n",
    "        self.inputs[\"REF\"] = 1.0\n",
    "        self.inputs[\"Insulin\"] = 1e-10\n",
    "\n",
    "        self.input_data = pd.DataFrame([\n",
    "            {'species': species, 'minconc': value*1e+12, 'value': value*1e+12, 'maxconc': value*1e+12}\n",
    "            for species, value in self.inputs.items()])\n",
    "\n",
    "    def gen_lookuptable(self) -> None:\n",
    "        self.lut = pd.concat([self.df_ranges, self.input_data], ignore_index=True)    # look-up-table\n",
    "        self.lut['species'] = self.lut['species'].str.upper()\n",
    "        print(f\"LUT was created successfully. Its dimensions are: {self.lut.shape}\")\n",
    "\n",
    "    def get_bounds(self) -> dict[str, tuple[float, float]]:\n",
    "        bounds = dict()\n",
    "        for index, row in self.df_ranges.iterrows():\n",
    "            if row.value < 0.1:\n",
    "                lb = 1e-14\n",
    "                ub = 1e-13\n",
    "            else:\n",
    "                lb = (row.value/2)*1e-12\n",
    "                ub = (row.value*1.5)*1e-12\n",
    "            bounds[row.species.upper()] = [lb, ub]\n",
    "        print(bounds['TBID'])\n",
    "        for index, row in self.input_data.iterrows():\n",
    "            if row.species.upper() not in bounds.keys():\n",
    "                bounds[row.species] = [row.minconc*1e-12, row.maxconc*1e-12]\n",
    "        for m in self.must_be_zero:\n",
    "            bounds[m.upper()] = [0, 0]\n",
    "        return bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac706b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, data_source, # data_source: a pandas DataFrame\n",
    "                 stresses: float, species_rng: Theoretical_Ranges,\n",
    "                 sheet_name: str, bibtex: str = \"\"):\n",
    "        self.rng = species_rng\n",
    "        if isinstance(data_source, pd.DataFrame): # Ha pandas DataFrame (azaz xlsx worksheet)\n",
    "            self.name = sheet_name\n",
    "            self.experiment_data = data_source.copy()\n",
    "        else:\n",
    "            raise ValueError(\"data_source must be a pandas DataFrame\")\n",
    "\n",
    "        self.stresses = stresses\n",
    "        self.bibtex = self.parse_bibtex(bibtex)\n",
    "        self.non_species_cols = {\"TIME\"}\n",
    "        self.process_data()\n",
    "\n",
    "    def parse_bibtex(self, bibtex_str):\n",
    "        parser = bibtexparser.loads(bibtex_str)\n",
    "        if not parser.entries:\n",
    "            raise ValueError(\"No valid BibTeX entry found.\")\n",
    "        entry = parser.entries[0]  # Assume only one entry is given\n",
    "\n",
    "        return {\n",
    "            \"author\": entry.get(\"author\", \"\"),\n",
    "            \"title\": entry.get(\"title\", \"\"),\n",
    "            \"journal\": entry.get(\"journal\", \"\"),\n",
    "            \"volume\": entry.get(\"volume\", \"\"),\n",
    "            \"number\": entry.get(\"number\", \"\"),\n",
    "            \"year\": entry.get(\"year\", \"\"),\n",
    "            \"doi\": entry.get(\"doi\", entry.get(\"url\", \"\"))  # fallback if no DOI\n",
    "        }\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        self.experiment_data.columns = [col.upper() for col in self.experiment_data.columns]\n",
    "        self.experiment_data.rename(columns={'TIME': 'time'}, inplace=True)\n",
    "        self.experiment_data.time = self.experiment_data.time #* 60  # Converting hrs to mins - if I convert, some xmls fail for some reaseon\n",
    "        self.experiment_data = self.experiment_data.dropna()\n",
    "        self.species = [v for v in self.experiment_data.columns if v.upper() not in self.non_species_cols and \"STD\" not in v.upper()]\n",
    "\n",
    "    def quantitated_exp_data(self, ics: dict[str, float]) -> None:\n",
    "        quant_Data = self.experiment_data.copy()\n",
    "        species_and_std = [col for col in quant_Data.columns if col.upper() not in self.non_species_cols]\n",
    "        for s in species_and_std:\n",
    "            if 'STD' in s.upper():\n",
    "                quant_Data[s] *= ics[s[0:-3]]\n",
    "            else:\n",
    "                quant_Data[s] *= ics[s]\n",
    "        self.quant_data = quant_Data\n",
    "\n",
    "    def check_compatibility(self) -> None:\n",
    "        for s in self.species:\n",
    "            if s.upper() not in self.rng.bounds.keys():\n",
    "                self.rng.bounds[s] = [0, 0]\n",
    "                print(f\"Creating new entry for {s}\\n\")\n",
    "            #else:\n",
    "            #    print('All compatible\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa0121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, species_range: Theoretical_Ranges, experiment: Experiment, max_digit = 4):\n",
    "        self.species_range = species_range\n",
    "        self.experiment = experiment\n",
    "        self.maxdigit = max_digit\n",
    "        self.experiment.check_compatibility()\n",
    "\n",
    "    def create_xml_files(self, output_xmls_path: str, num_of_xmls: int, xml_template_path: str) -> None:\n",
    "        if not os.path.exists(output_xmls_path):\n",
    "            os.makedirs(output_xmls_path)\n",
    "        self.num_of_xmls = num_of_xmls\n",
    "        env = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(xml_template_path)))\n",
    "        self.template = env.get_template(os.path.basename(xml_template_path))\n",
    "\n",
    "        for i in range(1, num_of_xmls+1):\n",
    "            np.random.seed(i)\n",
    "            self.random_ics = self.get_random_ics()\n",
    "            self.experiment.quantitated_exp_data(ics=self.random_ics)\n",
    "            self.make_xml_output(i, output_xmls_path)\n",
    "\n",
    "    def get_random_ics(self) -> dict[str, float]:\n",
    "        random_ics = {}\n",
    "        #random_ics = {s: np.random.uniform(*self.species_range.bounds[s]) for s in self.species_range.bounds}\n",
    "        inp_upper = [s.upper() for s in self.species_range.input_names]\n",
    "        mbz_upper = [s.upper() for s in self.species_range.must_be_zero]\n",
    "        for key in self.species_range.bounds:\n",
    "            if self.species_range.bounds[key][0] == 0 and self.species_range.bounds[key][1] == 0 and key not in inp_upper and key not in mbz_upper:\n",
    "                random_ics[key] = 1e-13\n",
    "            else:\n",
    "                random_ics[key] = np.random.uniform(*self.species_range.bounds[key])\n",
    "        random_ics['RAP'] = self.experiment.stresses\n",
    "        random_ics[\"REF\"] = 1.0\n",
    "        return random_ics\n",
    "\n",
    "    def make_xml_output(self, file_index: int, output_xmls_path: str) -> None:\n",
    "        dataPoints = [self.compileDataRow(row.values) for _, row in self.experiment.quant_data.iterrows()]\n",
    "        output = self.template.render(ics=self.random_ics, variables=self.experiment.species, dataPoints=dataPoints, bib=self.experiment.bibtex)\n",
    "        padded_number = str(file_index).zfill(self.maxdigit)\n",
    "        filename = f\"stressful_life_{padded_number}.xml\"\n",
    "        with open(os.path.join(output_xmls_path, filename), 'w') as f:\n",
    "            f.write(output)\n",
    "\n",
    "    def compileDataRow(self, dataPoints):\n",
    "        meas = \"\".join(f\"<{v}>{{:.4e}}</{v}>\" for v in self.experiment.experiment_data.columns)\n",
    "        return f\"<dataPoint>{meas.format(*dataPoints)}</dataPoint>\"\n",
    "\n",
    "    def generate_opp_content(self, xml_folder: str, name: str, mech_file: str,\n",
    "                             yaml_file: str, time_limit: int, thread_limit: int,\n",
    "                             settings_tag: str, solver: str) -> str:\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         BCRN6\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_cantera  {yaml_file}\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  BCRN6\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml_idx in range(1, self.num_of_xmls+1):\n",
    "          padded_number = str(xml_idx).zfill(self.maxdigit)\n",
    "          mechtest += f\"      NAME {xml_folder}/stressful_life_{padded_number}.xml\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    def gen_opp(self, output_dir, sheet_name, opp_output_dir, mech_file: str = \"7_Krisztian/mech/BCRN6.inp\",\n",
    "                yaml_file: str = \"7_Krisztian/mech/BCRN6.yaml\", time_limit: int = 50, thread_limit: int = 32,\n",
    "                settings_tag: str = \"systems_biology\", solver: str = \"cantera\"):\n",
    "        date = datetime.datetime.now()\n",
    "        opp_content = self.generate_opp_content(output_dir, sheet_name, mech_file, yaml_file, time_limit,\n",
    "                                                thread_limit, settings_tag, solver)  # Create .opp file content\n",
    "        opp_filename = f\"{date.year}{date.month}{date.day}_BCRN_{self.experiment.bibtex['author'].split()[0][:-1]}_{sheet_name}.opp\" # Define output .opp file path\n",
    "        with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "            f.write(opp_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa818e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rap': array([5.0e-07, 2.5e-07, 5.0e-08, 2.5e-08, 5.0e-09, 2.5e-09, 5.0e-10,\n",
       "        0.0e+00])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1e-12 scaling for mol/cm^3\n",
    "# uniformly dist. rap of [rap_input] nano mol     NOT     mol/dm^3 (= nM) cc.\n",
    "# in a volume of V = 10e-12 dm^3\n",
    "# uniformly \"absorbed\" by 2*10^5 cells\n",
    "rap_input = np.array([100, 50, 10, 5, 1, 0.5, 0.1, 0]) * 1e-12  # Converting to mol/cm^3 (=mol/mL)\n",
    "rap_in_cells = rap_input / (200000 * 1e-12 * 1e+3)  # rap_in_well_mol / (cell_num * V_cell_in_L * conversion_factor_to_mL)\n",
    "stress1 = 'rap'\n",
    "stresses: dict[str, NDArray[np.float_]] = {stress1: rap_in_cells}\n",
    "stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1c177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-14, 1e-13]\n",
      "LUT was created successfully. Its dimensions are: (85, 4)\n"
     ]
    }
   ],
   "source": [
    "input_names = ['nS', 'RAP', 'TG', 'dS', 'CCH', 'REF', 'Insulin', 'TG_SERCA', 'RKMTORA', 'casp', 'IP3R', 'Baxa', 'tBid']\n",
    "must_be_zero = ['casp', 'Baxa', 'tBid', 'p53a', 'PUMA']\n",
    "\n",
    "rng = Theoretical_Ranges('/home/nvme/Opt/7_Krisztian/0_evaluate/input_files/reactions_ics_finalised.xlsx',\n",
    "                         input_names, must_be_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f20cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_xlsx_path = '/home/nvme/Opt/7_Krisztian/0_evaluate/input_files/Nitin_rap.xlsx'\n",
    "xml_template = '/home/nvme/Opt/7_Krisztian/0_evaluate/input_files/xml_template.xml'\n",
    "\n",
    "# Parse stresses\n",
    "\n",
    "# Read all sheets from Excel\n",
    "all_sheets = pd.read_excel(exp_xlsx_path, sheet_name=None)  # dict of {sheet_name: DataFrame}\n",
    "\n",
    "# Extract BibTeX from the last sheet\n",
    "last_sheet_name = list(all_sheets.keys())[-1]\n",
    "bibtex_df = all_sheets[last_sheet_name]\n",
    "# Ha nem lenne header a BibTex-nel, akk ezzel kell beolvasni a sheetet: bibtex_df = pd.read_excel(exp_xlsx_path, sheet_name=last_sheet_name, header=None)\n",
    "\n",
    "# Join all non-empty strings from the first column into a BibTeX string\n",
    "bibtex_lines = bibtex_df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "bibtex_str = \"\\n\".join(bibtex_lines)\n",
    "bibtex_str = \"\\n\".join(bibtex_lines).replace(\"_x000d_\", \"\")  # Clean malformed carriage returns\n",
    "\n",
    "#print(\"BibTex:\\n\", bibtex_str, \"\\n\")\n",
    "opp_output_dir = '/home/nvme/Opt/7_Krisztian/1_mechtest'\n",
    "num_xml = 15\n",
    "\n",
    "for i, sheet_name in enumerate(list(all_sheets.keys())[:-1]):\n",
    "    df = all_sheets[sheet_name]\n",
    "    exp = Experiment(df, stresses['rap'][i], rng, sheet_name, bibtex_str)\n",
    "    output_dir = f\"/home/nvme/Opt/7_Krisztian/xml/{exp.bibtex['author'].split()[0][:-1]}_{exp.bibtex['year']}/{exp.name}\"\n",
    "    sim = Simulation(rng, exp)\n",
    "    sim.create_xml_files(output_dir, num_xml, xml_template)\n",
    "    sim.gen_opp(output_dir, sheet_name, opp_output_dir, mech_file=\"7_Krisztian/mech/BCRN_Nitin_rap.inp\",\n",
    "                yaml_file=\"7_Krisztian/mech/BCRN_Nitin_rap.yaml\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have to be in the folder where 'bin' is, or rewrite the commands below!!!!!!\n",
    "\n",
    "# bin/Release/OptimaPP 7_Krisztian/1_mechtest/2025625_BCRN_Beesabathuni_Rap_100_nM.opp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
