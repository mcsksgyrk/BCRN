{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c5c34aa5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from scipy import stats\n",
    "import os\n",
    "import datetime\n",
    "import subprocess\n",
    "from mech_dot_inp_gen import *\n",
    "from visualizations import *\n",
    "from optima import *\n",
    "import jinja2\n",
    "import copy\n",
    "from experiment_reader import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cda47d1d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Processing:\n",
    "    def __init__(self, species_txt: str, ) -> None:\n",
    "        self.species = self.get_species(species_txt)\n",
    "        #self.observables, self.not_observables = self.get_observables()\n",
    "        self.observables = ['ADP', 'AMP', 'AMPK', 'AMPKA', 'AMPKA_ADP',\n",
    "                            'AMPKA_AMP', 'AMPKA_ATP', 'AMPK_ADP', 'AMPK_AMP',\n",
    "                            'AMPK_ATP', 'ATP', 'FKBP12', 'GLUCIN', 'GLUCOUT',\n",
    "                            'MTOR', 'MTORA', 'RAP', 'RAPOUT', 'REF', 'RK',\n",
    "                            'RKMTORA', 'ULK', 'ULKA']\n",
    "        self.not_observables = list(set(self.species) - set(self.observables))\n",
    "\n",
    "    def get_species(self, species_txt: str) -> list[str]:\n",
    "        species = []\n",
    "        with open(species_txt, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for line in lines:\n",
    "            for s in line.strip().split():\n",
    "                species.append(s)\n",
    "        print(len(species), species)\n",
    "        return species\n",
    "\n",
    "    def get_observables(self) -> tuple[list[str], list[str]]:\n",
    "        dont_observe = []\n",
    "        for s in self.species:\n",
    "            if s == 'Q' or 'LKB1' in s or 'PP2A' in s or 'GLUT1' in s or 'RAP' in s or 'RK' in s or s in ['RHEB', 'PYRUVATE', 'AKT', 'TSCA']:\n",
    "                dont_observe.append(s)\n",
    "            elif s == 'FKBP12' or s == 'REF':\n",
    "                dont_observe.append(s)\n",
    "        observe = list(set(self.species) - set(dont_observe))\n",
    "        print(len(observe), observe)\n",
    "        return observe, dont_observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca166eb3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sheet_name: str, ics_df_path, # data_source: a pandas DataFrame\n",
    "                 dont_observe: list[str], time_points: list[float],\n",
    "                 time_course_vals: Union[dict[str, list[float]], float],\n",
    "                 food: str, bibtex_str: str=None, must_be_zero: list[str]=[],\n",
    "                 uncertainty=False, inputs: dict[str, float]={'GLUCOUT': 6e-6}, # dict[stress_species: init_cc] = [rap extracell.: [mol/cm^3]]\n",
    "                 experiment_data: Optional[str]=None) -> None:\n",
    "        self.model_name = sheet_name\n",
    "        self.ics_df = pd.read_csv(ics_df_path, sep=',')\n",
    "        self.ics_df['minconc'] = self.ics_df['minconc'].astype(float)\n",
    "        self.ics_df['maxconc'] = self.ics_df['maxconc'].astype(float)\n",
    "        self.ics_df['value'] = self.ics_df['value'].astype(float)\n",
    "        self.ics_df.species = [s.upper() for s in self.ics_df.species]\n",
    "        self.species = self.ics_df['species'].to_list()\n",
    "        self.output_species = list(set(self.species) - set(dont_observe))\n",
    "        self.time_points = time_points\n",
    "        if isinstance(time_course_vals, float):\n",
    "            self.time_course_vals = self.gen_time_course_vals(time_course_vals)\n",
    "        else:\n",
    "            self.time_course_vals = time_course_vals\n",
    "        self.food = food\n",
    "        self.must_be_zero = must_be_zero\n",
    "        self.uncertainty = uncertainty\n",
    "        self.inputs = inputs\n",
    "\n",
    "        self.ranges = self.get_bounds()\n",
    "        print(f\"range values stored in model.ranges of length {len(self.ranges.keys())}\")\n",
    "        self.get_sigmas()\n",
    "\n",
    "        # If no exp data given --> gen synthetic data\n",
    "        self.experiment_data = experiment_data\n",
    "        if experiment_data is not None:\n",
    "            for s in self.experiment_data.columns:\n",
    "                if 'STD' not in s.upper() and s.upper() != 'TIME' and s.upper() not in self.output_species:\n",
    "                    self.output_species.append(s.upper())\n",
    "            self.get_sigmas() # recalc sigmas in case new output species were added\n",
    "            self.get_experiment_data(experiment_data, bibtex_str)\n",
    "        else:\n",
    "            self.gen_exp_data()\n",
    "\n",
    "\n",
    "    def get_bounds(self) -> dict[str, tuple[float, float]]:\n",
    "        bounds = dict()\n",
    "        for _, row in self.ics_df.iterrows():\n",
    "            if 'REF' not in row.species and row.species not in self.must_be_zero:\n",
    "                if row.value < 1e-13:\n",
    "                    lb = 1e-14\n",
    "                    ub = 1e-13\n",
    "                elif row.minconc == row.maxconc: #as a consequence if sth is [0, 0] --> IC is 0\n",
    "                    lb = row.minconc\n",
    "                    ub = row.maxconc\n",
    "                else:\n",
    "                    if row.value/2 >= row.minconc:\n",
    "                        lb = (row.value/2)\n",
    "                    else:\n",
    "                        lb = row.minconc\n",
    "                    if row.value*1.5 <= row.maxconc:\n",
    "                        ub = (row.value*1.5)\n",
    "                    else:\n",
    "                        ub = row.maxconc\n",
    "            bounds[row.species.upper()] = [lb, ub]\n",
    "        return bounds\n",
    "\n",
    "    def get_sigmas(self):\n",
    "        self.sigmas = dict()\n",
    "        for key, value in self.ranges.items():\n",
    "            if self.uncertainty:\n",
    "                if key in self.must_be_zero: # this line might be unnecessary, as I think we need sigma only if the species is an output\n",
    "                    self.sigmas[key] = 0 #5e-18\n",
    "                elif key in self.output_species:\n",
    "                    if value[1] > value[0]:\n",
    "                        self.sigmas[key] = ((value[1]-value[0])/8)\n",
    "                    else:\n",
    "                        self.sigmas[key] = 5e-14\n",
    "            else:\n",
    "                self.sigmas[key] = 2.5e-13\n",
    "\n",
    "    def gen_time_course_vals(self, time_course_vals):\n",
    "        species_time_course = {}\n",
    "        for s in self.species:\n",
    "            species_time_course[s] = np.ones(len(self.time_points)) * time_course_vals\n",
    "        return species_time_course\n",
    "\n",
    "    def gen_exp_data(self):\n",
    "        self.exp_data = pd.DataFrame()\n",
    "        self.exp_data['time'] = self.time_points\n",
    "        for s in self.output_species:\n",
    "            self.exp_data[s] = self.ics_df[self.ics_df['species'] == s].iloc[0, 2] # \"exp_data\" = value of the csv column\n",
    "    \n",
    "    def get_experiment_data(self, experiment_data: pd.DataFrame, bibtex_str):\n",
    "        self.experiment = Experiment(experiment_data, \n",
    "                                     inputs=self.inputs,\n",
    "                                     species_sigmas=self.sigmas,\n",
    "                                     sheet_name=self.model_name,\n",
    "                                     bounds=self.ranges,\n",
    "                                     output_species=self.output_species,\n",
    "                                     ics_df=self.ics_df,\n",
    "                                     bibtex=bibtex_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "02059ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genesis:\n",
    "    def __init__(self, model: Model, max_digit = 4, prefix: str = \"stressful_life\"):\n",
    "        self.model = model\n",
    "        self.maxdigit = max_digit\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def create_xml_files(self, output_xmls_path: str, num_of_xmls: int,\n",
    "                         xml_template_path: str, prefix: str='', kiir=True) -> None:\n",
    "        if not os.path.exists(output_xmls_path):\n",
    "            os.makedirs(output_xmls_path)\n",
    "        self.num_xmls = num_of_xmls\n",
    "        self.output_dir = output_xmls_path\n",
    "        env = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(xml_template_path)))\n",
    "        self.template = env.get_template(os.path.basename(xml_template_path))\n",
    "\n",
    "        if kiir:\n",
    "            for i in range(1, num_of_xmls+1):\n",
    "                np.random.seed(i+1)\n",
    "                self.random_ics = self.get_random_ics()\n",
    "                if self.model.experiment_data is not None:\n",
    "                    self.model.exp_data = self.model.experiment.quantitated_exp_data(self.random_ics)\n",
    "                self.make_xml_output(i, output_xmls_path, prefix)\n",
    "\n",
    "    def get_random_ics(self) -> dict[str, float]:\n",
    "        random_ics = {}\n",
    "        if self.model.uncertainty:\n",
    "            for key in self.model.species:\n",
    "                if key not in self.model.must_be_zero:\n",
    "                    random_ics[key] = np.random.uniform(*self.model.ranges[key])\n",
    "                else:\n",
    "                    random_ics[key] = 0\n",
    "        else:\n",
    "           random_ics = dict(zip(self.model.ics_df['species'], self.model.ics_df['value']))\n",
    "        for key in self.model.inputs.keys():\n",
    "            random_ics[key] = self.model.inputs[key]\n",
    "        random_ics[\"REF\"] = 1.0\n",
    "        if 'no_gluc' not in self.model.food:\n",
    "            random_ics['Q'] = 6e-6\n",
    "        return random_ics\n",
    "\n",
    "    def make_xml_output(self, file_index: int, output_xmls_path: str, prefix) -> None:\n",
    "        dataPoints = [self.compileDataRow(row.values) for _, row in self.model.exp_data.iterrows()]\n",
    "        if self.model.experiment_data is not None:\n",
    "            output = self.template.render(ics=self.random_ics, variables=self.model.output_species,\n",
    "                                          dataPoints=dataPoints, bib=self.model.experiment.bibtex)\n",
    "        else:\n",
    "            output = self.template.render(ics=self.random_ics, relsigmas=self.model.sigmas,\n",
    "                                        variables=self.model.output_species, dataPoints=dataPoints)\n",
    "        padded_number = str(file_index).zfill(self.maxdigit)\n",
    "        filename = f\"{prefix}_{padded_number}.xml\"\n",
    "        with open(os.path.join(output_xmls_path, filename), 'w') as f:\n",
    "            f.write(output)\n",
    "\n",
    "    def compileDataRow(self, dataPoints):\n",
    "        meas = \"\".join(f\"<{v}>{{:.4e}}</{v}>\" for v in self.model.exp_data.columns)\n",
    "        return f\"<dataPoint>{meas.format(*dataPoints)}</dataPoint>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c1054d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, gen: Genesis, xmls_in_one_opp: int) -> None:\n",
    "      self.gen = gen\n",
    "      self.get_xml_vec(xmls_in_one_opp)\n",
    "\n",
    "    def get_xml_vec(self, xmls_in_one_opp) -> None:\n",
    "      self.xmls = []\n",
    "      for i in range(1, self.gen.num_xmls, xmls_in_one_opp):\n",
    "          xml_cnt = np.arange(i, i+xmls_in_one_opp, 1) \n",
    "          self.xmls.append(xml_cnt)\n",
    "\n",
    "    def opp_gen(self, opp_output_dir, opp_name_prefix, kiir, mech_file, food) -> None:\n",
    "      self.opps = []\n",
    "      self.indices = []\n",
    "      self.food = food\n",
    "      self.mech_file = mech_file\n",
    "      self.mech_inp_name = self.mech_file.split('/')[-1].split('.inp')[0]\n",
    "      for num in self.xmls:\n",
    "          opp_filename = f\"{opp_name_prefix}_{num[-1]}.opp\"\n",
    "          self.opps.append(opp_filename)\n",
    "          self.indices.append(f\"{num[-1]}\")\n",
    "          if kiir:\n",
    "            opp_content = self.generate_opp_content(xml_folder=self.gen.output_dir,\n",
    "                                                    num_xmls=num,\n",
    "                                                    mech_file=mech_file,\n",
    "                                                    name=self.gen.prefix)\n",
    "            with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "              f.write(opp_content)\n",
    "\n",
    "    def generate_opp_content(self, xml_folder: str, num_xmls: Union[list[int], list[list[int]]],\n",
    "                             mech_file: str, name: str, time_limit: int = 50, thread_limit: int = 32,\n",
    "                             settings_tag: str = \"systems_biology\", solver: str = \"cantera\") -> str:\n",
    "      mech_name = mech_file.split('/')[-1].split('.inp')[0]\n",
    "      yaml = mech_file.split('.inp')[0]\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         {mech_name}\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_{solver} {yaml}.yaml\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  {mech_name}\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "      PLOTS FALSE\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml in num_xmls:\n",
    "          padded_number = str(xml).zfill(self.gen.maxdigit)\n",
    "          mechtest += f\"      NAME {xml_folder}/{name}_{padded_number}.xml\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_opp_content_from_paths(xml_paths: list[str], mech_file: str,\n",
    "                                        time_limit: int = 50, thread_limit: int = 32,\n",
    "                                        settings_tag: str = \"systems_biology\", solver: str = \"cantera\") -> str:\n",
    "      mech_name = mech_file.split('/')[-1].split('.inp')[0]\n",
    "      yaml = mech_file.split('.inp')[0]\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         {mech_name}\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_{solver} {yaml}.yaml\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  {mech_name}\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "      PLOTS FALSE\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml_path in xml_paths:\n",
    "          mechtest += f\"      NAME {xml_path}\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    def sim_runner(self, log_location:str = ''):\n",
    "      self.parent_path = Path.cwd().parents[4] / \"OptimaPP\"\n",
    "\n",
    "      if log_location == '':\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "            command = [\"bin/Release/OptimaPP\", f\"../Projects/Semmelweis_BCRN/BCRN/1_mechtest/{opp_file}\"]\n",
    "            print(f\"Running: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, cwd=self.parent_path)\n",
    "      else:\n",
    "        if not os.path.exists(log_location):\n",
    "            os.makedirs(log_location)\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "          command = [\"bin/Release/OptimaPP\", f\"../Projects/Semmelweis_BCRN/BCRN/1_mechtest/{opp_file}\"]\n",
    "          print(f\"Running: {' '.join(command)}\")\n",
    "          log_idx = self.xmls[idx][-1]\n",
    "          with open(f\"{log_location}/run_log_stac_starve_rap_{self.food}_{log_idx}.txt\", \"w\") as log:\n",
    "              subprocess.run(command, check=True, stdout=log, stderr=subprocess.STDOUT, cwd=self.parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "582648bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Natural_Selection:\n",
    "    def __init__(self, sim: Simulation) -> None:\n",
    "        self.sim = sim\n",
    "        self.sim_data: dict[str, OptimaMechtest] = {}\n",
    "        self.get_sim_data()\n",
    "        #self.survival_of_the_fittest()\n",
    "\n",
    "    def get_sim_data(self) -> None:\n",
    "        for idx, key in enumerate(self.sim.indices):\n",
    "            self.sim_data[key] = OptimaMechtest(job_name=self.sim.opps[idx],\n",
    "                                                input_mech=self.sim.mech_inp_name)\n",
    "\n",
    "    def sigma_range(self, meas, sim, sigma):\n",
    "        radius = (sim-meas)/sigma\n",
    "        return radius\n",
    "    \n",
    "    def isit_init(self, row):\n",
    "        lut = self.sim.gen.model.ics_df\n",
    "        rel_sigmas = self.sim.gen.model.sigmas\n",
    "        for k, v in row.items():\n",
    "            if k in self.condition_vars:\n",
    "                right_row = lut[lut['species'] == k]\n",
    "\n",
    "                meas = right_row['value'].iloc[0]\n",
    "\n",
    "                radius = self.sigma_range(meas=meas, sim=v, sigma=rel_sigmas[k])\n",
    "\n",
    "                if radius >= 4:\n",
    "                    self.wrongdoers[k] += 1\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def survival_of_the_fittest(self) -> None:\n",
    "        self.good_xmls = []\n",
    "        self.get_condition_vars()\n",
    "        self.wrongdoers = {k: 0 for k in self.condition_vars}\n",
    "        for idx in self.sim.indices:\n",
    "            for xml_name, row in self.sim_data[idx].df_followed18.iterrows():\n",
    "                all_ok = self.isit_init(row)\n",
    "                if all_ok:\n",
    "                    self.good_xmls.append(xml_name)\n",
    "        print(f\"Found {len(self.good_xmls)} good xmls\")\n",
    "\n",
    "    def get_condition_vars(self) -> None:\n",
    "        self.condition_vars = ['RHEBA', 'AKTA', 'TSC', 'MTORA', 'ATP', 'ULK', 'GLUCIN']\n",
    "# too big LKB1 activity could mean upregged AMPK biologically speaking\n",
    "# ADP, AMP make complexes just like ATP, but for AMP/ADP the complex concentrations are comparable to the\n",
    "# cc. of either ADP or AMP --> complex-bound ADP/AMP would throw the calculation off\n",
    "# LKB1 and PP2A form complexes with the AMPKs --> their cc. should change --> not adequate conditions\n",
    "    def filtering(self) -> None:\n",
    "        data = copy.deepcopy(self.sim_data)\n",
    "        first = True\n",
    "        self.filtered_basal = pd.DataFrame()\n",
    "        self.filtered_followed = pd.DataFrame()\n",
    "        for k, v in data.items():\n",
    "            v.df_basal.index = v.df_basal.index.str[7:-9]\n",
    "            v.df_basal = v.df_basal.sort_index()\n",
    "            if first:\n",
    "                self.filtered_basal = v.df_basal[[xml in self.good_xmls for xml in v.df_basal.index]]\n",
    "                self.filtered_followed = v.df_followed18[[xml in self.good_xmls for xml in v.df_followed18.index]]\n",
    "                first = False\n",
    "            else:\n",
    "                self.filtered_basal = pd.concat([self.filtered_basal, v.df_basal[[xml in self.good_xmls for xml in v.df_basal.index]]],\n",
    "                                        ignore_index=False)\n",
    "                self.filtered_followed = pd.concat([self.filtered_followed, v.df_followed18[[xml in self.good_xmls for xml in v.df_followed18.index]]],\n",
    "                                            ignore_index=False)\n",
    "\n",
    "    def get_cov_cor(self, corr_xmls, keys: list[str]) -> None:\n",
    "        self.dict_b = {}\n",
    "        self.dict_f = {}\n",
    "        self.dict_b_corr = {}\n",
    "        self.dict_f_corr = {}\n",
    "        self.dict_b_cov = {}\n",
    "        self.dict_f_cov = {}\n",
    "        for idx, alma in enumerate(corr_xmls):\n",
    "            self.dict_f[f\"{keys[idx]}\"] = self.filtered_followed.iloc[alma].copy()\n",
    "            #self.dict_b[f\"{keys[idx]}\"] = self.filtered_basal.iloc[alma].copy()\n",
    "            #self.dict_b_corr[f\"{keys[idx]}\"] = self.filtered_basal.iloc[alma].copy().corr()\n",
    "            self.dict_f_corr[f\"{keys[idx]}\"] = self.filtered_followed.iloc[alma].copy().corr()\n",
    "            self.dict_f_cov[f\"{keys[idx]}\"] = self.filtered_followed.iloc[alma].copy().cov()\n",
    "            #self.dict_b_cov[f\"{keys[idx]}\"] = self.filtered_basal.iloc[alma].copy().cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c15f9385",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_correlation_distance_heatmap(dict, corr_xmls, title: str, method='fro',\n",
    "                                      save_fig=False, nat_select:Natural_Selection=None):\n",
    "    num_corrs = len(corr_xmls)\n",
    "    distance_matrix = np.zeros((num_corrs, num_corrs))\n",
    "\n",
    "    for i, n1 in enumerate(corr_xmls):\n",
    "        for j, n2 in enumerate(corr_xmls):\n",
    "            mat1 = dict[str(n1)].values\n",
    "            mat2 = dict[str(n2)].values\n",
    "            if method == 'kl':\n",
    "                mu1 = nat_select.dict_f[str(n1)].mean()\n",
    "                mu2 = nat_select.dict_f[str(n2)].mean()\n",
    "                distance_matrix[i, j] = compute_matrix_distance(mat1, mat2, method=method, mu1=mu1, mu2=mu2)\n",
    "            else:\n",
    "                distance_matrix[i, j] = compute_matrix_distance(mat1, mat2, method=method)\n",
    "    plot_it(distance_matrix, corr_xmls, corr_xmls, method, save_fig, title)\n",
    "\n",
    "def plot_dual_metric_heatmap(dict, keys,\n",
    "                              method_lower='cmd', method_upper='frobenius',\n",
    "                              title='Dual Distance Plot',\n",
    "                              cmap_lower='Blues', cmap_upper='Reds',\n",
    "                              save_fig=False,\n",
    "                              nat_select_dict: dict[str, pd.DataFrame] = None):\n",
    "    n = len(keys)\n",
    "    data_lower = np.zeros((n, n))\n",
    "    data_upper = np.zeros((n, n))\n",
    "\n",
    "    # Compute both metrics for all pairs\n",
    "    for i, n1 in enumerate(keys):\n",
    "        for j, n2 in enumerate(keys):\n",
    "            mat1 = dict[str(n1)]\n",
    "            mat2 = dict[str(n2)]\n",
    "            if method_lower == 'kl' or method_upper == 'kl':\n",
    "                mu1 = nat_select_dict[str(n1)].mean()\n",
    "                mu2 = nat_select_dict[str(n2)].mean()\n",
    "            if i >= j:\n",
    "                data_lower[i, j] = compute_matrix_distance(mat1, mat2, method_lower, mu1=mu1, mu2=mu2)\n",
    "            elif i < j:\n",
    "                data_upper[i, j] = compute_matrix_distance(mat1, mat2, method_upper, mu1=mu1, mu2=mu2)\n",
    "\n",
    "    # Create masks\n",
    "    mask_lower = np.triu(np.ones_like(data_lower, dtype=bool), k=1)\n",
    "    mask_upper = np.tril(np.ones_like(data_upper, dtype=bool), k=0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Plot lower triangle\n",
    "    norm_lower = Normalize(vmin=np.min(data_lower[np.tril_indices(n, -1)]),\n",
    "                           vmax=np.max(data_lower[np.tril_indices(n, -1)]))\n",
    "    sns.heatmap(data_lower,\n",
    "                mask=mask_lower,\n",
    "                cmap=cmap_lower,\n",
    "                annot=True,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                ax=ax)\n",
    "\n",
    "    plt.xlabel('Number of XMLs')\n",
    "    plt.ylabel('Number of XMLs')\n",
    "\n",
    "    # Plot upper triangle\n",
    "    norm_upper = Normalize(vmin=np.min(data_upper[np.triu_indices(n, 1)]),\n",
    "                           vmax=np.max(data_upper[np.triu_indices(n, 1)]))\n",
    "    sns.heatmap(data_upper,\n",
    "                mask=mask_upper,\n",
    "                cmap=cmap_upper,\n",
    "                annot=True,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar=False,\n",
    "                xticklabels=keys,\n",
    "                yticklabels=keys,\n",
    "                ax=ax)\n",
    "\n",
    "    ax.set_xticklabels(keys, rotation=45, ha='right', fontsize=9)\n",
    "    ax.set_yticklabels(keys, rotation=0, fontsize=9)\n",
    "    ax.set_title(title, fontsize=14, pad=12)\n",
    "\n",
    "    # Add both colorbars\n",
    "    cbar_ax1 = fig.add_axes([0.84, 0.25, 0.02, 0.5])  # Right colorbar\n",
    "    sm1 = cm.ScalarMappable(cmap=cmap_upper, norm=norm_upper)\n",
    "    sm1.set_array([])\n",
    "    cbar1 = fig.colorbar(sm1, cax=cbar_ax1)\n",
    "    cbar1.set_label(f'{method_upper.upper()} (upper)', rotation=270, labelpad=15)\n",
    "\n",
    "    cbar_ax2 = fig.add_axes([0.0, 0.25, 0.02, 0.5])  # Left colorbar\n",
    "    sm2 = cm.ScalarMappable(cmap=cmap_lower, norm=norm_lower)\n",
    "    sm2.set_array([])\n",
    "    cbar2 = fig.colorbar(sm2, cax=cbar_ax2)\n",
    "    cbar2.set_label(f'{method_lower.upper()} (lower)', rotation=90, labelpad=15)\n",
    "\n",
    "    #fig.patch.set_facecolor('#f8f6f6')\n",
    "    #plt.tight_layout(rect=[0.1, 0, 0.9, 1])\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(f\"pics/{title.replace(' ', '_')}.png\", dpi=300)\n",
    "        plt.savefig(f\"pics/{title.replace(' ', '_')}.pdf\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_distance_heatmap_leodit(dict, corr_xmls, title: str, method='frobenius',\n",
    "                                      save_fig=False, nat_select:Natural_Selection=None):\n",
    "    num_corrs = len(corr_xmls)\n",
    "    distance_matrix = np.zeros((num_corrs, num_corrs))\n",
    "\n",
    "    for i, n1 in enumerate(corr_xmls):\n",
    "        for j, n2 in enumerate(corr_xmls):\n",
    "            mat1 = dict[str(n1)]\n",
    "            mat2 = dict[str(n2)]\n",
    "            if method == 'kl':\n",
    "                mu1 = nat_select.dict_b[str(n1)].mean()\n",
    "                mu2 = nat_select.dict_b[str(n2)].mean()\n",
    "                distance_matrix[i, j] = compute_matrix_distance(mat1, mat2, method=method, mu1=mu1, mu2=mu2)\n",
    "            else:\n",
    "                distance_matrix[i, j] = compute_matrix_distance(mat1, mat2, method=method)\n",
    "    plot_it(distance_matrix, corr_xmls, corr_xmls, method, save_fig, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "517c64b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 ['AC', 'AC_GA', 'AC_GAA', 'ADP', 'AKT', 'AKTA', 'AMP', 'AMPK', 'AMPKA', 'AMPKA_ADP', 'AMPKA_ADP_PP2A', 'AMPKA_AMP', 'AMPKA_AMP_PP2A', 'AMPKA_ATP', 'AMPKA_ATP_PP2A', 'AMPKA_PP2A', 'AMPK_ADP', 'AMPK_ADP_LKB1', 'AMPK_AMP', 'AMPK_AMP_LKB1', 'AMPK_ATP', 'AMPK_ATP_LKB1', 'AMPK_LKB1', 'ATG5', 'ATG5T', 'ATG5_BCL2', 'ATP', 'AUT', 'BAX', 'BAXA', 'BCL2', 'BCL2_BAX', 'BCL2_PUMA', 'BEC1', 'BEC1A', 'BEC1_BCL2', 'BEC1_UVG', 'BID', 'CA2ER', 'CA2IC', 'CALPAIN', 'CALPAINA', 'CAMKKB', 'CAMKKBA', 'CAMP', 'CASP', 'CCH', 'CYTC', 'CYTCM', 'DAPK', 'DAPKA', 'DRAM', 'DS', 'EPAC', 'EPACA', 'FKBP12', 'GA', 'GAA', 'GABC', 'GBC', 'GLUCIN', 'GLUCOUT', 'GLUT1', 'GLUT1_GLUCIN', 'GLUT1_GLUCOUT', 'GPCRA', 'INSULIN', 'IP3', 'IP3R', 'IP3R_BCL2', 'IP3R_IP3', 'LKB1', 'MDM2', 'MTOR', 'MTORA', 'MTOR_RAP', 'NS', 'P53', 'P53A', 'P53A_BCL2', 'PHAG', 'PI3K', 'PI3KA', 'PIP2', 'PKA', 'PKAA', 'PKC', 'PKC_CA2IC', 'PLCE', 'PLCEA', 'PP2A', 'PREAUT', 'PROCASP', 'PUMA', 'PYRUVATE', 'Q', 'RAP', 'RAPOUT', 'REF', 'RHEB', 'RHEBA', 'RK', 'RKMTORA', 'SERCA', 'SERCAA', 'TBID', 'TG', 'TG_SERCA', 'TSC', 'TSCA', 'ULK', 'ULKA', 'UVG', 'UVG_BAX']\n",
      "23 ['ADP', 'AMP', 'AMPK', 'AMPKA', 'AMPKA_ADP', 'AMPKA_AMP', 'AMPKA_ATP', 'AMPK_ADP', 'AMPK_AMP', 'AMPK_ATP', 'ATP', 'FKBP12', 'GLUCIN', 'GLUCOUT', 'MTOR', 'MTORA', 'RAP', 'RAPOUT', 'REF', 'RK', 'RKMTORA', 'ULK', 'ULKA']\n"
     ]
    }
   ],
   "source": [
    "proc = Processing('../input_files/unique_species.txt')\n",
    "print(len(proc.observables), proc.observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac5ca318",
   "metadata": {},
   "outputs": [],
   "source": [
    "gluc_rap = pd.read_csv('../input_files/gluc_rap_ranges.csv')\n",
    "combined = pd.read_csv('../input_files/combined_ranges.csv')\n",
    "\n",
    "cols = [\"minconc\", \"maxconc\", \"value\"]\n",
    "combined[cols] *= 1e-12\n",
    "\n",
    "combined.to_csv('../input_files/combined_ranges_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8debea5",
   "metadata": {},
   "source": [
    "## Gen XML Data from Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c64591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Casp\n",
      "range values stored in model.ranges of length 103\n",
      "cyt\n",
      "range values stored in model.ranges of length 103\n"
     ]
    }
   ],
   "source": [
    "exp_xlsx_path = '../input_files/Mattiolo_2015_tester.xlsx'\n",
    "xml_template = '../input_files/xml_template.xml'\n",
    "\n",
    "# Parse stresses\n",
    "\n",
    "# Read all sheets from Excel\n",
    "all_sheets = pd.read_excel(exp_xlsx_path, sheet_name=None)  # dict of {sheet_name: DataFrame}\n",
    "\n",
    "# Extract BibTeX from the last sheet\n",
    "last_sheet_name = list(all_sheets.keys())[-1]\n",
    "bibtex_df = all_sheets[last_sheet_name]\n",
    "# Ha nem lenne header a BibTex-nel, akk ezzel kell beolvasni a sheetet: bibtex_df = pd.read_excel(exp_xlsx_path, sheet_name=last_sheet_name, header=None)\n",
    "\n",
    "# Join all non-empty strings from the first column into a BibTeX string\n",
    "bibtex_lines = bibtex_df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "bibtex_str = \"\\n\".join(bibtex_lines)\n",
    "bibtex_str = \"\\n\".join(bibtex_lines).replace(\"_x000d_\", \"\")  # Clean malformed carriage returns\n",
    "\n",
    "#print(\"BibTex:\\n\", bibtex_str, \"\\n\")\n",
    "opp_output_dir = '../../1_mechtest'\n",
    "num_xmls = 10\n",
    "\n",
    "all_xml_paths = []\n",
    "\n",
    "date = datetime.datetime.now()\n",
    "date_prefix = f\"{date.year}{date.month}{date.day}\"\n",
    "\n",
    "must_be_zero = ['Baxa', 'PUMA', 'RAP', 'RAPOUT', 'RK', 'RKMTORA', 'casp', 'p53a', 'tBid']\n",
    "inputs = {'RAPOUT': 0}\n",
    "inputs['GLUCOUT'] = 6e-6  # 6 mM glucose\n",
    "food = 'gluc_no_rap' # bc we have glucose, but also rap (could be: gluc_no_rap, gluc_rap, no_gluc_no_rap, no_gluc_rap)\n",
    "\n",
    "t = np.arange(0, 5070, 30)\n",
    "sims: dict[str, Simulation] = {}\n",
    "\n",
    "for i, sheet_name in enumerate(sorted(list(all_sheets.keys())[:-1])):  # Exclude the last sheet (BibTeX)\n",
    "    print(sheet_name)\n",
    "    df = all_sheets[sheet_name]\n",
    "\n",
    "    mod = Model(sheet_name=sheet_name, ics_df_path='../input_files/combined_ranges_scaled.csv',\n",
    "                dont_observe=proc.not_observables, time_points=t, time_course_vals=7e-10,\n",
    "                uncertainty=True, must_be_zero=must_be_zero, inputs=inputs, food=food,\n",
    "                experiment_data=df, bibtex_str=bibtex_str)\n",
    "\n",
    "    output_dir = f\"/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/xml/{mod.experiment.bibtex['author'].split()[0][:-1]}_{mod.experiment.bibtex['year']}/{mod.experiment.name}\"\n",
    "    prefix = f\"{mod.model_name}\"\n",
    "\n",
    "    gen = Genesis(mod, max_digit=4, prefix=prefix)\n",
    "    gen.create_xml_files(output_xmls_path=output_dir,\n",
    "                         num_of_xmls=num_xmls,\n",
    "                         xml_template_path=xml_template,\n",
    "                         prefix=prefix, kiir=True)\n",
    "\n",
    "    sim = Simulation(gen, num_xmls)\n",
    "    sim.opp_gen(opp_output_dir='/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/1_mechtest',\n",
    "                opp_name_prefix=f'{date_prefix}_{prefix}_{food}',\n",
    "                kiir=True, mech_file='/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/mech/starve_rap_combined.inp',\n",
    "                food=food)\n",
    "\n",
    "    sims[prefix] = sim\n",
    "\n",
    "#for key, sim in sims.items():\n",
    "#    sim.sim_runner(log_location=f'/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/logs/{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d16e0b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/szupernikusz/OptimaPP/outputs/2026131_Casp_gluc_rap_10.opp/mechTestResults_starve_rap_combined.csv\n",
      "True\n",
      "/home/szupernikusz/OptimaPP/outputs/2026131_cyt_gluc_rap_10.opp/mechTestResults_starve_rap_combined.csv\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mechs: dict[str, OptimaMechtest] = {}\n",
    "for k in sims.keys():\n",
    "    mechs[k] = OptimaMechtest(sims[k].opps[0], sims[k].mech_inp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdb77b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Casp_0001':            CASP\n",
       " 1  7.645510e-14\n",
       " 2  7.701880e-14\n",
       " 3  7.758650e-14\n",
       " 4  7.815830e-14\n",
       " 5  7.873420e-14\n",
       " 6  7.950850e-14\n",
       " 7  8.107970e-14,\n",
       " 'Casp_0002':             CASP\n",
       " 8   8.578840e-14\n",
       " 9   8.701560e-14\n",
       " 10  8.825990e-14\n",
       " 11  8.952170e-14\n",
       " 12  9.080120e-14\n",
       " 13  9.253570e-14\n",
       " 14  9.610380e-14,\n",
       " 'Casp_0003':             CASP\n",
       " 15  4.280920e-14\n",
       " 16  4.326490e-14\n",
       " 17  4.372500e-14\n",
       " 18  4.418980e-14\n",
       " 19  4.465940e-14\n",
       " 20  4.529320e-14\n",
       " 21  4.658740e-14,\n",
       " 'Casp_0004':             CASP\n",
       " 22  5.305000e-14\n",
       " 23  5.385670e-14\n",
       " 24  5.467530e-14\n",
       " 25  5.550590e-14\n",
       " 26  5.634900e-14\n",
       " 27  5.749280e-14\n",
       " 28  5.984970e-14,\n",
       " 'Casp_0005':             CASP\n",
       " 29  2.840670e-14\n",
       " 30  2.866370e-14\n",
       " 31  2.892290e-14\n",
       " 32  2.918430e-14\n",
       " 33  2.944790e-14\n",
       " 34  2.980310e-14\n",
       " 35  3.052610e-14,\n",
       " 'Casp_0006':             CASP\n",
       " 36  1.365890e-14\n",
       " 37  1.379600e-14\n",
       " 38  1.393430e-14\n",
       " 39  1.407370e-14\n",
       " 40  1.421430e-14\n",
       " 41  1.440390e-14\n",
       " 42  1.479040e-14,\n",
       " 'Casp_0007':             CASP\n",
       " 43  6.060470e-14\n",
       " 44  6.166580e-14\n",
       " 45  6.274490e-14\n",
       " 46  6.384260e-14\n",
       " 47  6.495920e-14\n",
       " 48  6.647810e-14\n",
       " 49  6.962270e-14,\n",
       " 'Casp_0008':             CASP\n",
       " 50  1.927460e-14\n",
       " 51  1.940960e-14\n",
       " 52  1.954540e-14\n",
       " 53  1.968200e-14\n",
       " 54  1.981950e-14\n",
       " 55  2.000430e-14\n",
       " 56  2.037900e-14,\n",
       " 'Casp_0009':             CASP\n",
       " 57  1.578240e-14\n",
       " 58  1.603340e-14\n",
       " 59  1.628790e-14\n",
       " 60  1.654600e-14\n",
       " 61  1.680800e-14\n",
       " 62  1.716340e-14\n",
       " 63  1.789650e-14,\n",
       " 'Casp_0010':             CASP\n",
       " 64  2.737130e-14\n",
       " 65  2.760050e-14\n",
       " 66  2.783140e-14\n",
       " 67  2.806400e-14\n",
       " 68  2.829850e-14\n",
       " 69  2.861410e-14\n",
       " 70  2.925560e-14}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mechs['Casp'].orig_time_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6302e272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range values stored in model.ranges of length 103\n",
      "range values stored in model.ranges of length 103\n",
      "range values stored in model.ranges of length 103\n",
      "range values stored in model.ranges of length 103\n"
     ]
    }
   ],
   "source": [
    "must_be_zero = ['Baxa', 'PUMA', 'RAP', 'RAPOUT', 'RK', 'RKMTORA', 'casp', 'p53a', 'tBid']\n",
    "inputs = {'RAPOUT': 0}\n",
    "inputs['GLUCOUT'] = 6e-6  # 6 mM glucose\n",
    "exp_conds = ['gluc_no_rap', 'gluc_rap', 'no_gluc_no_rap', 'no_gluc_rap'] # bc we have glucose, but also rap (could be: gluc_no_rap, gluc_rap, no_gluc_no_rap, no_gluc_rap)\n",
    "\n",
    "inputs_vec = [{'GLUCOUT': 6e-6, 'RAPOUT': 0},           # Az entry-k a vectorban eggyezzenek a conditionokkel\n",
    "              {'GLUCOUT': 6e-6, 'RAPOUT': 1e-10},\n",
    "              {'GLUCOUT': 1e-6, 'RAPOUT': 0},\n",
    "              {'GLUCOUT': 1e-6, 'RAPOUT': 1e-10}]\n",
    "\n",
    "\n",
    "must_be_zero = ['RAP', 'RK', 'RKMTORA', 'RAPOUT']\n",
    "date = datetime.datetime.now()\n",
    "date_prefix = f\"{date.year}{date.month}{date.day}\"\n",
    "t = np.arange(0, 5070, 30)\n",
    "sims: dict[str, Simulation] = {}\n",
    "\n",
    "num_xmls = 10\n",
    "xml_template = '../input_files/std_xml_template.xml'\n",
    "\n",
    "for i, cond in enumerate(exp_conds):\n",
    "\n",
    "    mod = Model(sheet_name=cond, ics_df_path='../input_files/combined_ranges_scaled.csv',\n",
    "                dont_observe=proc.not_observables, time_points=t, time_course_vals=7e-10,\n",
    "                uncertainty=True, must_be_zero=must_be_zero, inputs=inputs_vec[i],\n",
    "                food=cond)\n",
    "\n",
    "    output_dir = f'/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/xml/testing_combined_{cond}'\n",
    "    prefix = f\"{mod.model_name}\"\n",
    "\n",
    "    gen = Genesis(mod, max_digit=4, prefix=prefix)\n",
    "    gen.create_xml_files(output_xmls_path=output_dir,\n",
    "                         num_of_xmls=num_xmls,\n",
    "                         xml_template_path=xml_template,\n",
    "                         prefix=prefix, kiir=True)\n",
    "\n",
    "    sim = Simulation(gen, num_xmls)\n",
    "    sim.opp_gen(opp_output_dir='/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/1_mechtest',\n",
    "                opp_name_prefix=f'{date_prefix}_testing_{cond}',\n",
    "                kiir=True, mech_file='/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/mech/starve_rap_combined.inp',\n",
    "                food=cond)\n",
    "\n",
    "    sims[cond] = sim\n",
    "\n",
    "#for key, sim in sims.items():\n",
    "#    sim.sim_runner(log_location=f'/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/logs/{key}')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
