{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50dad775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import subprocess\n",
    "from filegenerators import *\n",
    "pd.options.display.float_format = '{:.2e}'.format\n",
    "from pathlib import Path\n",
    "import os\n",
    "import bibtexparser\n",
    "from numpy.typing import NDArray\n",
    "from typing import Dict, List, Union, Optional\n",
    "from mech_dot_inp_gen import *\n",
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "237cd6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimaOutput:\n",
    "    def __init__(self, job_name: Union[str, Path],\n",
    "                 optima_path: Optional[Union[str, Path]] = None):\n",
    "\n",
    "        self.job_name = str(job_name)\n",
    "        if optima_path == None:\n",
    "            self.optima_path = Path(\"/home/szupernikusz/OptimaPP/outputs\")\n",
    "        self.job_folder = self.optima_path / job_name\n",
    "        file_path = self.job_folder / \"mechanismInfo.txt\"\n",
    "        try:\n",
    "            with open(file_path, \"r\") as f:\n",
    "                self.mech_info = f.read()\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cb25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimaMechtest(OptimaOutput):\n",
    "    def __init__(self, job_name: Union[str, Path],\n",
    "                 input_mech: str,\n",
    "                 optima_path: Optional[Union[str, Path]] = None,\n",
    "                 errf_type: Union[str, List[str]] = \"default\"):\n",
    "        super().__init__(job_name, optima_path)\n",
    "\n",
    "        self._errf_files = {\n",
    "           \"default\": \"errfValues\",\n",
    "           \"data_series\": \"errfValues_by_data_series\", \n",
    "           \"points\": \"errfValues_by_points\",\n",
    "           \"species\": \"errfValues_by_species\"\n",
    "            }\n",
    "\n",
    "        if (self.job_folder / \"debug\").exists():\n",
    "            self.all_data = {}\n",
    "            for csv_data in (self.job_folder / \"debug\").glob(\"*.csv\"):\n",
    "                try:\n",
    "                    self.all_data[csv_data.stem] = pd.read_csv(csv_data)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        print((self.job_folder / f\"mechTestResults_{input_mech}.csv\"))\n",
    "        if (self.job_folder / f\"mechTestResults_{input_mech}.csv\").exists():\n",
    "            print((self.job_folder / f\"mechTestResults_{input_mech}.csv\").exists())\n",
    "            self.all_sheets_dP = pd.read_csv(self.job_folder / f\"mechTestResults_{input_mech}.csv\",  # dP as in the info in dataPoints\n",
    "                                        header=None,\n",
    "                                        delimiter=';',\n",
    "                                        index_col=False,\n",
    "                                        names=['xml', 'time_point', 'species', 'dP_val', 'sim_val'],\n",
    "                                        )#low_memory=False)\n",
    "            #print(self.all_sheets_dP)\n",
    "            self.get_coarse_df(all_sheets_dP=self.all_sheets_dP)\n",
    "\n",
    "        stac_eq_df = pd.concat({k: v.iloc[-1] for k, v in self.all_data.items()}, axis=1)                # makes a dict() with the\n",
    "        #followed18 = pd.concat({k: v.iloc[-1] for k, v in self.orig_time_sim_df.items()}, axis=1)        # same keys, the values are\n",
    "        self.df_basal = stac_eq_df.iloc[3:-1].T                                                          # the last elements i.e.,\n",
    "        #self.df_followed18 = followed18.T                                                                # t = last time_point\n",
    "\n",
    "    def __str__(self):\n",
    "        if not self.df_basal.empty and not self.df_followed18.empty:\n",
    "            return f\"Mech object was successfully generated with fields\\ndf_basal: {self.df_basal.shape}\\ndf_followed18: {self.df_followed18.shape}\"\n",
    "        elif self.df_basal.empty and not self.df_followed18.empty:\n",
    "            return \"Unsuccessful, error with df_basal\"\n",
    "        elif not self.df_basal.empty and self.df_followed18.empty:\n",
    "            return \"Unsuccessful, error with df_followed18\"\n",
    "        else:\n",
    "            return \"Mech object was not successfully created\"\n",
    "\n",
    "    def get_coarse_df(self, all_sheets_dP):\n",
    "        self.orig_time_sim_df = {}\n",
    "        self.orig_time_exp_df = {}\n",
    "\n",
    "        time_point = 0\n",
    "        species = 'ilyen_species_tuti_nem_lesz'\n",
    "        self.failed_sims_xmls = []\n",
    "\n",
    "        for _, row in all_sheets_dP.iterrows():\n",
    "            if row.xml in self.failed_sims_xmls:\n",
    "                continue\n",
    "\n",
    "            xml_name = row.xml\n",
    "            sim_val = row.sim_val\n",
    "            exp_val = row.dP_val\n",
    "\n",
    "            if row.species == species:\n",
    "                time_point += 1\n",
    "            else:\n",
    "                species = row.species\n",
    "                time_point = 1\n",
    "\n",
    "            if sim_val != 'FAILED':\n",
    "                # ensure dict entries exist\n",
    "                if xml_name not in self.orig_time_sim_df:\n",
    "                    self.orig_time_sim_df[xml_name] = pd.DataFrame()\n",
    "                if xml_name not in self.orig_time_exp_df:\n",
    "                    self.orig_time_exp_df[xml_name] = pd.DataFrame()\n",
    "\n",
    "                # ALWAYS assign (no else:)\n",
    "                self.orig_time_sim_df[xml_name].loc[time_point, species] = float(sim_val)\n",
    "                self.orig_time_exp_df[xml_name].loc[time_point, species] = exp_val\n",
    "            else:\n",
    "                self.failed_sims_xmls.append(xml_name)\n",
    "\n",
    "        # make sure rows are in time order and numeric\n",
    "        for xml, df in self.orig_time_sim_df.items():\n",
    "            self.orig_time_sim_df[xml] = df.sort_index().apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # build “followed18” as last valid values per species\n",
    "        followed18 = pd.concat(\n",
    "            {xml: df.ffill().iloc[-1]              # or: df.apply(lambda c: c.dropna().iloc[-1])\n",
    "            for xml, df in self.orig_time_sim_df.items()},\n",
    "            axis=1\n",
    "        )\n",
    "        self.df_followed18 = followed18.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50066ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theoretical_Ranges:\n",
    "    def __init__(self, min_max_path: str, input_names: list[str], must_be_zero: list[str],\n",
    "                 scaling_factor: float=1e-12, sheet_name:str = 'icranges'):\n",
    "        self.name = os.path.splitext(os.path.basename(min_max_path))[0]\n",
    "        self.df_ranges = pd.read_excel(min_max_path, sheet_name=sheet_name)\n",
    "        self.df_ranges['value'] = self.df_ranges['value'].astype(float)\n",
    "        self.df_ranges.species = [s.upper() for s in self.df_ranges.species]\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.df_scaled_ranges = self.df_ranges.select_dtypes(include='number') * self.scaling_factor\n",
    "        self.must_be_zero = must_be_zero\n",
    "        self.input_names = input_names\n",
    "        self.get_input_data(input_names)\n",
    "        self.bounds = self.get_bounds()\n",
    "        self.get_sigmas()\n",
    "        self.gen_lookuptable()\n",
    "\n",
    "    def get_input_data(self, input_names: list[str]) -> None:\n",
    "        self.inputs = {}\n",
    "        for i in input_names:\n",
    "            self.inputs[i] = 0.0\n",
    "        self.inputs[\"REF\"] = 1.0\n",
    "        self.inputs[\"Insulin\"] = 1e-10\n",
    "\n",
    "        self.input_data = pd.DataFrame([\n",
    "            {'species': species, 'minconc': value*1e+12, 'value': value*1e+12, 'maxconc': value*1e+12}\n",
    "            for species, value in self.inputs.items()])\n",
    "\n",
    "    def gen_lookuptable(self) -> None:\n",
    "        self.lut = pd.concat([self.df_ranges, self.input_data], ignore_index=True)    # look-up-table\n",
    "        self.lut['species'] = self.lut['species'].str.upper()\n",
    "        print(f\"LUT was created successfully. Its dimensions are: {self.lut.shape}\")\n",
    "\n",
    "    def get_bounds(self) -> dict[str, tuple[float, float]]:\n",
    "        bounds = dict()\n",
    "        for index, row in self.df_ranges.iterrows():\n",
    "            if row.value < 0.1:\n",
    "                lb = 1e-14\n",
    "                ub = 1e-13\n",
    "            else:\n",
    "                lb = (row.value/2)*1e-12\n",
    "                ub = (row.value*1.5)*1e-12\n",
    "            bounds[row.species.upper()] = [lb, ub]\n",
    "        print(bounds['TBID'])\n",
    "        for _, row in self.input_data.iterrows():\n",
    "            if row.species.upper() not in bounds.keys():\n",
    "                bounds[row.species.upper()] = [row.minconc*1e-12, row.maxconc*1e-12]\n",
    "        for m in self.must_be_zero:\n",
    "            bounds[m.upper()] = [0, 0]\n",
    "        return bounds\n",
    "\n",
    "    def get_sigmas(self):\n",
    "        self.sigmas = dict()\n",
    "        for key, value in self.bounds.items():\n",
    "            if key in self.must_be_zero: # this line might be unnecessary, as I think we need sigma only if the species is an output\n",
    "                self.sigmas[key] = 5e-18\n",
    "            if value[1] > value[0]:\n",
    "                self.sigmas[key] = ((value[1]-value[0])/8)\n",
    "            else:\n",
    "                self.sigmas[key] = 5e-15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac706b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, data_source, # data_source: a pandas DataFrame\n",
    "                 stresses: float, species_rng: Theoretical_Ranges,\n",
    "                 sheet_name: str, bibtex: str = \"\", inputs: dict[str, float] = {}):\n",
    "        self.rng = species_rng\n",
    "        if isinstance(data_source, pd.DataFrame): # Ha pandas DataFrame (azaz xlsx worksheet)\n",
    "            self.name = sheet_name\n",
    "            self.experiment_data = data_source.copy()\n",
    "        else:\n",
    "            raise ValueError(\"data_source must be a pandas DataFrame\")\n",
    "\n",
    "        self.stresses = stresses\n",
    "        self.bibtex = self.parse_bibtex(bibtex)\n",
    "        self.non_species_cols = {\"TIME\"}\n",
    "        \n",
    "        self.inputs = self.get_exp_inputs(inputs)\n",
    "        self.process_data()\n",
    "\n",
    "    def parse_bibtex(self, bibtex_str):\n",
    "        parser = bibtexparser.loads(bibtex_str)\n",
    "        if not parser.entries:\n",
    "            raise ValueError(\"No valid BibTeX entry found.\")\n",
    "        entry = parser.entries[0]  # Assume only one entry is given\n",
    "\n",
    "        return {\n",
    "            \"author\": entry.get(\"author\", \"\"),\n",
    "            \"title\": entry.get(\"title\", \"\"),\n",
    "            \"journal\": entry.get(\"journal\", \"\"),\n",
    "            \"volume\": entry.get(\"volume\", \"\"),\n",
    "            \"number\": entry.get(\"number\", \"\"),\n",
    "            \"year\": entry.get(\"year\", \"\"),\n",
    "            \"doi\": entry.get(\"doi\", entry.get(\"url\", \"\"))  # fallback if no DOI\n",
    "        }\n",
    "\n",
    "    def get_exp_inputs(self, inputs) -> dict[str, float]:\n",
    "        for name in self.rng.input_names:\n",
    "            if name not in inputs.keys():\n",
    "                inputs[name] = self.rng.inputs[name]\n",
    "        return inputs\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        self.experiment_data.columns = [col.upper() for col in self.experiment_data.columns]\n",
    "        self.experiment_data.rename(columns={'TIME': 'time'}, inplace=True)\n",
    "        self.experiment_data.time = self.experiment_data.time #* 60  # Converting hrs to mins - if I convert, some xmls fail for some reaseon\n",
    "        self.experiment_data = self.experiment_data.dropna()\n",
    "        self.species = [v for v in self.experiment_data.columns if v.upper() not in self.non_species_cols and \"STD\" not in v.upper()]\n",
    "\n",
    "    def quantitated_exp_data(self, ics: dict[str, float]) -> None:\n",
    "        quant_Data = self.experiment_data.copy()\n",
    "        #species_and_std = [col for col in quant_Data.columns if col.upper() not in self.non_species_cols]\n",
    "        #for s in species_and_std:\n",
    "        #    if 'STD' in s.upper():\n",
    "        #        quant_Data[s] *= ics[s[0:-3]]\n",
    "        #    #elif f\"{s}_STD\" not in species_and_std:\n",
    "        #    else:\n",
    "        #        quant_Data[s] *= ics[s]\n",
    "\n",
    "        for col in quant_Data.columns:\n",
    "            if col.upper() not in self.non_species_cols:\n",
    "                if 'STD' in col.upper():\n",
    "                    quant_Data[col] *= ics[col[0:-4].upper()]\n",
    "                else:\n",
    "                    quant_Data[col] *= ics[col.upper()]\n",
    "                if 'STD' not in col.upper() and f\"{col}_STD\" not in quant_Data.columns:\n",
    "                    # add a new column called f\"{col}_STD\" filled with self.rng.sigmas[col.upper()]\n",
    "                    quant_Data[f\"{col}_STD\"] = self.rng.sigmas[col.upper()]\n",
    "\n",
    "        self.quant_data = quant_Data\n",
    "\n",
    "    def check_compatibility(self) -> None:\n",
    "        for s in self.species:\n",
    "            if s.upper() not in self.rng.bounds.keys():\n",
    "                self.rng.bounds[s] = [0, 0]\n",
    "                print(f\"Creating new entry for {s}\\n\")\n",
    "            #else:\n",
    "            #    print('All compatible\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef3bbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Genesis:\n",
    "    def __init__(self, experiment: Experiment, max_digit = 4, prefix: str = \"stressful_life\"):\n",
    "        self.experiment = experiment\n",
    "        self.maxdigit = max_digit\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def create_xml_files(self, output_xmls_path: str, num_xmls: int, xml_template_path: str) -> None:\n",
    "        self.output_dir = output_xmls_path\n",
    "        if not os.path.exists(output_xmls_path):\n",
    "            os.makedirs(output_xmls_path)\n",
    "        self.num_xmls = num_xmls\n",
    "        env = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(xml_template_path)))\n",
    "        self.template = env.get_template(os.path.basename(xml_template_path))\n",
    "\n",
    "        for i in range(1, num_xmls+1):\n",
    "            np.random.seed(i)\n",
    "            self.random_ics = self.get_random_ics()\n",
    "            self.experiment.quantitated_exp_data(ics=self.random_ics)\n",
    "            self.make_xml_output(i, output_xmls_path)\n",
    "\n",
    "    def get_random_ics(self) -> dict[str, float]:\n",
    "        random_ics = {}\n",
    "        for key in self.experiment.rng.bounds.keys():\n",
    "            if key not in self.experiment.rng.must_be_zero:\n",
    "                random_ics[key] = np.random.uniform(*self.experiment.rng.bounds[key])\n",
    "            else:\n",
    "                random_ics[key] = 0\n",
    "        for key in self.experiment.inputs.keys():\n",
    "            random_ics[key] = self.experiment.inputs[key]\n",
    "        random_ics[\"REF\"] = 1.0\n",
    "        return random_ics\n",
    "\n",
    "    def make_xml_output(self, file_index: int, output_xmls_path: str) -> None:\n",
    "        dataPoints = [self.compileDataRow(row.values) for _, row in self.experiment.quant_data.iterrows()]\n",
    "        self.datP_check = dataPoints\n",
    "        output = self.template.render(ics=self.random_ics, variables=self.experiment.species,\n",
    "                                      dataPoints=dataPoints, bib=self.experiment.bibtex)\n",
    "        padded_number = str(file_index).zfill(self.maxdigit)\n",
    "        filename = f\"{self.prefix}_{padded_number}.xml\"\n",
    "        with open(os.path.join(output_xmls_path, filename), 'w') as f:\n",
    "            f.write(output)\n",
    "\n",
    "    def compileDataRow(self, dataPoints):\n",
    "        meas = \"\".join(f\"<{v}>{{:.4e}}</{v}>\" for v in self.experiment.quant_data.columns)\n",
    "        return f\"<dataPoint>{meas.format(*dataPoints)}</dataPoint>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fa0121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, gen: Genesis, xmls_in_one_opp: int) -> None:\n",
    "      self.gen = gen\n",
    "      self.get_xml_vec(xmls_in_one_opp)\n",
    "\n",
    "    def get_xml_vec(self, xmls_in_one_opp) -> None:\n",
    "      self.xmls = []\n",
    "      for i in range(1, self.gen.num_xmls, xmls_in_one_opp):\n",
    "          xml_cnt = np.arange(i, i+xmls_in_one_opp, 1) \n",
    "          self.xmls.append(xml_cnt)\n",
    "\n",
    "    def opp_gen(self, opp_output_dir, opp_name_prefix, kiir, mech_file, food) -> None:\n",
    "      self.opps = []\n",
    "      self.indices = []\n",
    "      self.food = food\n",
    "      self.mech_file = mech_file\n",
    "      self.mech_inp_name = self.mech_file.split('/')[-1].split('.inp')[0]\n",
    "      for num in self.xmls:\n",
    "          opp_filename = f\"{opp_name_prefix}_{num[-1]}.opp\"\n",
    "          self.opps.append(opp_filename)\n",
    "          self.indices.append(f\"{num[-1]}\")\n",
    "          if kiir:\n",
    "            opp_content = self.generate_opp_content(xml_folder=self.gen.output_dir,\n",
    "                                                    num_xmls=num,\n",
    "                                                    mech_file=mech_file,\n",
    "                                                    name=self.gen.prefix)\n",
    "            with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "              f.write(opp_content)\n",
    "\n",
    "    def generate_opp_content(self, xml_folder: str, num_xmls: Union[list[int], list[list[int]]],\n",
    "                             mech_file: str, name: str, time_limit: int = 50, thread_limit: int = 32,\n",
    "                             settings_tag: str = \"systems_biology\", solver: str = \"cantera\") -> str:\n",
    "      mech_name = mech_file.split('/')[-1].split('.inp')[0]\n",
    "      yaml = mech_file.split('.inp')[0]\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         {mech_name}\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_{solver} {yaml}.yaml\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  {mech_name}\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "      PLOTS FALSE\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml in num_xmls:\n",
    "          padded_number = str(xml).zfill(self.gen.maxdigit)\n",
    "          mechtest += f\"      NAME {xml_folder}/{name}_{padded_number}.xml\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_opp_content_from_paths(xml_paths: list[str], mech_file: str,\n",
    "                                        time_limit: int = 50, thread_limit: int = 32,\n",
    "                                        settings_tag: str = \"systems_biology\", solver: str = \"cantera\") -> str:\n",
    "      mech_name = mech_file.split('/')[-1].split('.inp')[0]\n",
    "      yaml = mech_file.split('.inp')[0]\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         {mech_name}\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_{solver} {yaml}.yaml\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  {mech_name}\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "      PLOTS FALSE\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml_path in xml_paths:\n",
    "          mechtest += f\"      NAME {xml_path}\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n",
    "\n",
    "    def sim_runner(self, log_location:str = ''):\n",
    "      self.parent_path = Path.cwd().parents[2]\n",
    "\n",
    "      if log_location == '':\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "            command = [\"bin/Release/OptimaPP\", f\"7_Krisztian/1_mechtest/{opp_file}\"]\n",
    "            print(f\"Running: {' '.join(command)}\")\n",
    "            subprocess.run(command, check=True, cwd=self.parent_path)\n",
    "      else:\n",
    "        for idx, opp_file in enumerate(self.opps):\n",
    "          command = [\"bin/Release/OptimaPP\", f\"7_Krisztian/1_mechtest/{opp_file}\"]\n",
    "          print(f\"Running: {' '.join(command)}\")\n",
    "          log_idx = self.xmls[idx][-1]\n",
    "          with open(f\"{log_location}/run_log_stac_starve_rap{log_idx}.txt\", \"w\") as log:\n",
    "              subprocess.run(command, check=True, stdout=log, stderr=subprocess.STDOUT, cwd=self.parent_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa818e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rap': array([5.0e-07, 2.5e-07, 5.0e-08, 2.5e-08, 5.0e-09, 2.5e-09, 5.0e-10,\n",
       "        0.0e+00])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1e-12 scaling for mol/cm^3\n",
    "# uniformly dist. rap of [rap_input] nano mol     NOT     mol/dm^3 (= nM) cc.\n",
    "# in a volume of V = 10e-12 dm^3\n",
    "# uniformly \"absorbed\" by 2*10^5 cells\n",
    "rap_input = np.array([100, 50, 10, 5, 1, 0.5, 0.1, 0]) * 1e-12  # Converting to mol/cm^3 (=mol/mL)\n",
    "rap_in_cells = rap_input / (200000 * 1e-12 * 1e+3)  # rap_in_well_mol / (cell_num * V_cell_in_L * conversion_factor_to_mL)\n",
    "stress1 = 'rap'\n",
    "stresses: dict[str, NDArray[np.float64]] = {stress1: rap_in_cells}\n",
    "stresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e1c177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1e-14, 1e-13]\n",
      "LUT was created successfully. Its dimensions are: (121, 4)\n"
     ]
    }
   ],
   "source": [
    "input_names = ['RAPOUT', 'TG', 'CCH', 'REF', 'Insulin', 'TG_SERCA', 'RKMTORA', 'casp', 'IP3R', 'Baxa', 'tBid']\n",
    "must_be_zero = ['casp', 'Baxa', 'tBid', 'p53a', 'PUMA', 'RAP', 'RK']\n",
    "\n",
    "rng = Theoretical_Ranges('../input_files/theoretical_combined_ranges.xlsx',\n",
    "                         input_names, must_be_zero, sheet_name='combined_ranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17cc208b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.875e-10, 5.625e-10] [1.875e-10, 5.625e-10]\n"
     ]
    }
   ],
   "source": [
    "# FKBP12 set to MTORA ranges\n",
    "print(rng.bounds['FKBP12'], rng.bounds['MTORA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f20cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_xlsx_path = '../input_files/Nitin_rap.xlsx'\n",
    "xml_template = '../input_files/xml_template.xml'\n",
    "\n",
    "# Parse stresses\n",
    "\n",
    "# Read all sheets from Excel\n",
    "all_sheets = pd.read_excel(exp_xlsx_path, sheet_name=None)  # dict of {sheet_name: DataFrame}\n",
    "\n",
    "# Extract BibTeX from the last sheet\n",
    "last_sheet_name = list(all_sheets.keys())[-1]\n",
    "bibtex_df = all_sheets[last_sheet_name]\n",
    "# Ha nem lenne header a BibTex-nel, akk ezzel kell beolvasni a sheetet: bibtex_df = pd.read_excel(exp_xlsx_path, sheet_name=last_sheet_name, header=None)\n",
    "\n",
    "# Join all non-empty strings from the first column into a BibTeX string\n",
    "bibtex_lines = bibtex_df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "bibtex_str = \"\\n\".join(bibtex_lines)\n",
    "bibtex_str = \"\\n\".join(bibtex_lines).replace(\"_x000d_\", \"\")  # Clean malformed carriage returns\n",
    "\n",
    "#print(\"BibTex:\\n\", bibtex_str, \"\\n\")\n",
    "opp_output_dir = '../../1_mechtest'\n",
    "num_xmls = 10\n",
    "\n",
    "all_xml_paths = []\n",
    "\n",
    "date = datetime.datetime.now()\n",
    "date_prefix = f\"{date.year}{date.month}{date.day}\"\n",
    "\n",
    "for i, sheet_name in enumerate(list(all_sheets.keys())[:-1]):\n",
    "    df = all_sheets[sheet_name]\n",
    "    exp = Experiment(df, stresses['rap'][i], rng, sheet_name, bibtex_str, inputs={'RAPOUT': 1e-10})\n",
    "    output_dir = f\"/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/xml/{exp.bibtex['author'].split()[0][:-1]}_{exp.bibtex['year']}/{exp.name}\"\n",
    "    gen = Genesis(exp, max_digit=4, prefix=f\"alma{exp.name}\")\n",
    "    gen.create_xml_files(output_dir, num_xmls, xml_template)\n",
    "\n",
    "    for xml in range(1, num_xmls + 1):\n",
    "        padded_number = str(xml).zfill(gen.maxdigit)\n",
    "        all_xml_paths.append(f\"{output_dir}/{gen.prefix}_{padded_number}.xml\")\n",
    "\n",
    "opp_filename = f\"{date_prefix}_all_setups.opp\"\n",
    "opp_content = Simulation.generate_opp_content_from_paths(\n",
    "    xml_paths=all_xml_paths,\n",
    "    mech_file='/home/szupernikusz/Projects/Semmelweis_BCRN/BCRN/mech/starve_rap_combined.inp',\n",
    ")\n",
    "\n",
    "with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "    f.write(opp_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a68abcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>CYTC</th>\n",
       "      <th>CYTC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.50e-15</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2.33e-14</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>5.28e-14</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time     CYTC  CYTC_STD\n",
       "0     0 3.50e-15  1.13e-14\n",
       "1     8 2.33e-14  1.13e-14\n",
       "2    22 5.28e-14  1.13e-14"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.quant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8859565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique species: 114\n"
     ]
    }
   ],
   "source": [
    "# unique_species.py\n",
    "\n",
    "# Read the input file\n",
    "with open(\"../input_files/species.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Split on any whitespace and create a set\n",
    "species_set = set(text.split())\n",
    "\n",
    "# (Optional) sort for nicer output\n",
    "unique_species = sorted(species_set)\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of unique species: {len(unique_species)}\")\n",
    "\n",
    "# (Optional) save to a file\n",
    "with open(\"../input_files/unique_species.txt\", \"w\") as f:\n",
    "    for s in unique_species:\n",
    "        f.write(s + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c564ef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_inp(list(species_set), out_path='../../mech/dummy.inp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1401b266",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcrn6_ranges = pd.read_csv('../input_files/BCRN6_ranges.csv')\n",
    "gluc_rap_ranges = pd.read_csv('../input_files/gluc_rap_ranges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f023019e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>minconc</th>\n",
       "      <th>value</th>\n",
       "      <th>maxconc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AC_Ga</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AC_Gaa</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AKT</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AKTa</td>\n",
       "      <td>5.00e+01</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  minconc  value  maxconc\n",
       "0      AC 1.00e+02    200      400\n",
       "1   AC_Ga 0.00e+00      0        0\n",
       "2  AC_Gaa 0.00e+00      0        0\n",
       "3     AKT 0.00e+00      0        0\n",
       "4    AKTa 5.00e+01    100      200"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcrn6_ranges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebf0ea31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>minconc</th>\n",
       "      <th>value</th>\n",
       "      <th>maxconc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PYRUVATE</td>\n",
       "      <td>2.00e+04</td>\n",
       "      <td>3.30e+04</td>\n",
       "      <td>4.00e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>1.00e+03</td>\n",
       "      <td>1.00e+03</td>\n",
       "      <td>1.00e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATP</td>\n",
       "      <td>3.00e+06</td>\n",
       "      <td>5.00e+06</td>\n",
       "      <td>7.00e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>5.00e+04</td>\n",
       "      <td>1.25e+05</td>\n",
       "      <td>2.00e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMP</td>\n",
       "      <td>5.00e+02</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>5.00e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  minconc    value  maxconc\n",
       "0  PYRUVATE 2.00e+04 3.30e+04 4.00e+04\n",
       "1         Q 1.00e+03 1.00e+03 1.00e+03\n",
       "2       ATP 3.00e+06 5.00e+06 7.00e+06\n",
       "3       ADP 5.00e+04 1.25e+05 2.00e+05\n",
       "4       AMP 5.00e+02 2.50e+03 5.00e+03"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gluc_rap_ranges['minconc'] = gluc_rap_ranges['minconc'].astype(float) * 1e+12\n",
    "gluc_rap_ranges['value'] = gluc_rap_ranges['value'].astype(float) * 1e+12\n",
    "gluc_rap_ranges['maxconc'] = gluc_rap_ranges['maxconc'].astype(float) * 1e+12\n",
    "gluc_rap_ranges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ae7ed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>minconc</th>\n",
       "      <th>value</th>\n",
       "      <th>maxconc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PYRUVATE</td>\n",
       "      <td>2.00e+04</td>\n",
       "      <td>3.30e+04</td>\n",
       "      <td>4.00e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q</td>\n",
       "      <td>1.00e+03</td>\n",
       "      <td>1.00e+03</td>\n",
       "      <td>1.00e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATP</td>\n",
       "      <td>3.00e+06</td>\n",
       "      <td>5.00e+06</td>\n",
       "      <td>7.00e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADP</td>\n",
       "      <td>5.00e+04</td>\n",
       "      <td>1.25e+05</td>\n",
       "      <td>2.00e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMP</td>\n",
       "      <td>5.00e+02</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>5.00e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>preAUT</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>procasp</td>\n",
       "      <td>1.20e+01</td>\n",
       "      <td>2.40e+01</td>\n",
       "      <td>4.80e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>tBid</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>PKC</td>\n",
       "      <td>5.00e+01</td>\n",
       "      <td>1.00e+02</td>\n",
       "      <td>2.00e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>PKC_Ca2ic</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       species  minconc    value  maxconc\n",
       "0     PYRUVATE 2.00e+04 3.30e+04 4.00e+04\n",
       "1            Q 1.00e+03 1.00e+03 1.00e+03\n",
       "2          ATP 3.00e+06 5.00e+06 7.00e+06\n",
       "3          ADP 5.00e+04 1.25e+05 2.00e+05\n",
       "4          AMP 5.00e+02 2.50e+03 5.00e+03\n",
       "..         ...      ...      ...      ...\n",
       "105     preAUT 0.00e+00 0.00e+00 0.00e+00\n",
       "106    procasp 1.20e+01 2.40e+01 4.80e+01\n",
       "107       tBid 0.00e+00 0.00e+00 0.00e+00\n",
       "108        PKC 5.00e+01 1.00e+02 2.00e+02\n",
       "109  PKC_Ca2ic 0.00e+00 0.00e+00 0.00e+00\n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ranges = gluc_rap_ranges.copy()\n",
    "for index, row in bcrn6_ranges.iterrows():\n",
    "    if row['species'] not in gluc_rap_ranges['species'].values:\n",
    "        combined_ranges = pd.concat([combined_ranges, pd.DataFrame([row])], ignore_index=True)\n",
    "combined_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdb5dea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_species = combined_ranges['species'].str.upper().tolist()\n",
    "set(combined_species) - species_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85439e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ranges.to_csv('../input_files/combined_ranges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7997491a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AC',\n",
       " 'AC_GA',\n",
       " 'AC_GAA',\n",
       " 'ADP',\n",
       " 'AKT',\n",
       " 'AKTA',\n",
       " 'AMP',\n",
       " 'AMPK',\n",
       " 'AMPKA',\n",
       " 'AMPKA_ADP',\n",
       " 'AMPKA_ADP_PP2A',\n",
       " 'AMPKA_AMP',\n",
       " 'AMPKA_AMP_PP2A',\n",
       " 'AMPKA_ATP',\n",
       " 'AMPKA_ATP_PP2A',\n",
       " 'AMPKA_PP2A',\n",
       " 'AMPK_ADP',\n",
       " 'AMPK_ADP_LKB1',\n",
       " 'AMPK_AMP',\n",
       " 'AMPK_AMP_LKB1',\n",
       " 'AMPK_ATP',\n",
       " 'AMPK_ATP_LKB1',\n",
       " 'AMPK_LKB1',\n",
       " 'ATG5',\n",
       " 'ATG5T',\n",
       " 'ATG5_BCL2',\n",
       " 'ATP',\n",
       " 'AUT',\n",
       " 'BAX',\n",
       " 'BAXA',\n",
       " 'BCL2',\n",
       " 'BCL2_BAX',\n",
       " 'BCL2_PUMA',\n",
       " 'BEC1',\n",
       " 'BEC1A',\n",
       " 'BEC1_BCL2',\n",
       " 'BEC1_UVG',\n",
       " 'BID',\n",
       " 'CA2ER',\n",
       " 'CA2IC',\n",
       " 'CALPAIN',\n",
       " 'CALPAINA',\n",
       " 'CAMKKB',\n",
       " 'CAMKKBA',\n",
       " 'CAMP',\n",
       " 'CASP',\n",
       " 'CCH',\n",
       " 'CYTC',\n",
       " 'CYTCM',\n",
       " 'DAPK',\n",
       " 'DAPKA',\n",
       " 'DRAM',\n",
       " 'DS',\n",
       " 'EPAC',\n",
       " 'EPACA',\n",
       " 'FKBP12',\n",
       " 'GA',\n",
       " 'GAA',\n",
       " 'GABC',\n",
       " 'GBC',\n",
       " 'GLUCIN',\n",
       " 'GLUCOUT',\n",
       " 'GLUT1',\n",
       " 'GLUT1_GLUCIN',\n",
       " 'GLUT1_GLUCOUT',\n",
       " 'GPCRA',\n",
       " 'INSULIN',\n",
       " 'IP3',\n",
       " 'IP3R',\n",
       " 'IP3R_BCL2',\n",
       " 'IP3R_IP3',\n",
       " 'LKB1',\n",
       " 'MDM2',\n",
       " 'MTOR',\n",
       " 'MTORA',\n",
       " 'MTOR_RAP',\n",
       " 'NS',\n",
       " 'P53',\n",
       " 'P53A',\n",
       " 'P53A_BCL2',\n",
       " 'PHAG',\n",
       " 'PI3K',\n",
       " 'PI3KA',\n",
       " 'PIP2',\n",
       " 'PKA',\n",
       " 'PKAA',\n",
       " 'PKC',\n",
       " 'PKC_CA2IC',\n",
       " 'PLCE',\n",
       " 'PLCEA',\n",
       " 'PP2A',\n",
       " 'PREAUT',\n",
       " 'PROCASP',\n",
       " 'PUMA',\n",
       " 'PYRUVATE',\n",
       " 'Q',\n",
       " 'RAP',\n",
       " 'RAPOUT',\n",
       " 'REF',\n",
       " 'RHEB',\n",
       " 'RHEBA',\n",
       " 'RK',\n",
       " 'RKMTORA',\n",
       " 'SERCA',\n",
       " 'SERCAA',\n",
       " 'TBID',\n",
       " 'TG',\n",
       " 'TG_SERCA',\n",
       " 'TSC',\n",
       " 'TSCA',\n",
       " 'ULK',\n",
       " 'ULKA',\n",
       " 'UVG',\n",
       " 'UVG_BAX'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_set\n",
    "# I have to be in the folder where 'bin' is, or rewrite the commands below!!!!!!\n",
    "\n",
    "# bin/Release/OptimaPP 7_Krisztian/1_mechtest/2025625_BCRN_Beesabathuni_Rap_100_nM.opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d6425d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>CYTC</th>\n",
       "      <th>CYTC_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.50e-15</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2.33e-14</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>5.28e-14</td>\n",
       "      <td>1.13e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time     CYTC  CYTC_STD\n",
       "0     0 3.50e-15  1.13e-14\n",
       "1     8 2.33e-14  1.13e-14\n",
       "2    22 5.28e-14  1.13e-14"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim.gen.experiment.quant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1d259af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<dataPoint><time>0.0000e+00</time><CYTC>3.5037e-15</CYTC><CYTC_STD>1.1250e-14</CYTC_STD></dataPoint>',\n",
       " '<dataPoint><time>8.0000e+00</time><CYTC>2.3289e-14</CYTC><CYTC_STD>1.1250e-14</CYTC_STD></dataPoint>',\n",
       " '<dataPoint><time>2.2000e+01</time><CYTC>5.2762e-14</CYTC><CYTC_STD>1.1250e-14</CYTC_STD></dataPoint>']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.datP_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
