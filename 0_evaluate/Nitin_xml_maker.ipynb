{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50dad775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from filegenerators import *\n",
    "from typing import Dict, List, Union, Optional\n",
    "pd.options.display.float_format = '{:.2e}'.format\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "from CovCor_calc import OptimaMechtest, OptimaOutput, OptimaSensitivity\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "from scipy.linalg import sqrtm, logm\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "import bibtexparser\n",
    "from typing import Dict\n",
    "from numpy.typing import NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac706b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, data_source, # data_source: either a string (path to CSV) or a pandas DataFrame\n",
    "                 stresses: dict[str, NDArray[np.float_]],\n",
    "                 bibtex: str = \"\"):\n",
    "\n",
    "        if isinstance(data_source, str):    # Ha .csv filename\n",
    "            self.name = os.path.splitext(os.path.basename(data_source))[0]\n",
    "            self.experiment_data = pd.read_csv(data_source)\n",
    "        elif isinstance(data_source, pd.DataFrame): # Ha pandas DataFrame (azaz xlsx worksheet)\n",
    "            self.name = \"worksheet_experiment\"\n",
    "            self.experiment_data = data_source.copy()\n",
    "        else:\n",
    "            raise ValueError(\"data_source must be a file path or a pandas DataFrame\")\n",
    "\n",
    "        self.stresses = stresses\n",
    "        self.bibtex = self.parse_bibtex(bibtex)\n",
    "        self.non_species_cols = {\"TIME\"}\n",
    "        self.process_data()\n",
    "\n",
    "    def parse_bibtex(self, bibtex_str):\n",
    "        parser = bibtexparser.loads(bibtex_str)\n",
    "        entry = parser.entries[0]  # Assume only one entry is given\n",
    "\n",
    "        return {\n",
    "            \"author\": entry.get(\"author\", \"\"),\n",
    "            \"title\": entry.get(\"title\", \"\"),\n",
    "            \"journal\": entry.get(\"journal\", \"\"),\n",
    "            \"volume\": entry.get(\"volume\", \"\"),\n",
    "            \"number\": entry.get(\"number\", \"\"),\n",
    "            \"year\": entry.get(\"year\", \"\"),\n",
    "            \"doi\": entry.get(\"doi\", entry.get(\"url\", \"\"))  # fallback if no DOI\n",
    "        }\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        self.experiment_data.columns = [col.upper() for col in self.experiment_data.columns]\n",
    "        self.experiment_data.rename(columns={'TIME': 'time'}, inplace=True)\n",
    "        self.experiment_data = self.experiment_data.dropna()\n",
    "        self.species = [v for v in self.experiment_data.columns if v.upper() not in self.non_species_cols and \"STD\" not in v.upper()]\n",
    "\n",
    "    def quantitated_exp_data(self, ics: dict[str, float]) -> None:\n",
    "        quant_Data = self.experiment_data.copy()\n",
    "        species_and_std = [col for col in quant_Data.columns if col.upper() not in self.non_species_cols]\n",
    "        for s in species_and_std:\n",
    "            if 'STD' in s.upper():\n",
    "                quant_Data[s] *= ics[s[0:-3]]\n",
    "            else:\n",
    "                quant_Data[s] *= ics[s]\n",
    "        self.quant_data = quant_Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f70512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Theoretical_Ranges:\n",
    "    def __init__(self, min_max_path: str, scaling_factor: float, first_species_col: int):\n",
    "        self.name = os.path.splitext(os.path.basename(min_max_path))[0]\n",
    "        if min_max_path.endswith('.csv'):\n",
    "            self.df_ranges = pd.read_csv(min_max_path)\n",
    "        elif min_max_path.endswith('.xlsx'):\n",
    "            self.df_ranges = pd.read_excel(min_max_path, sheet_name=\"testics\")\n",
    "        self.scaling_factor = scaling_factor\n",
    "        self.df_scaled_ranges = self.df_ranges.select_dtypes(include='number') * self.scaling_factor\n",
    "        self.bounds = self.get_bounds(first_species_col)\n",
    "\n",
    "    def get_bounds(self, first_species_col) -> dict[str, tuple[float, float]]:\n",
    "        bounds: dict[str, tuple[float, float]] = {}\n",
    "        for col in self.df_scaled_ranges.iloc[:, first_species_col-1:]:\n",
    "            lb, ub = self.df_scaled_ranges[col][:2]\n",
    "            if lb == '' or lb < 0:\n",
    "                lb = 0\n",
    "            if ub == '' or ub < 0:\n",
    "                ub = 0\n",
    "            col = col.replace('x_', '')\n",
    "            bounds[col.upper()] = [lb, ub]\n",
    "        return bounds\n",
    "\n",
    "    def check_compatibility(self, experiment: Experiment) -> None:\n",
    "        for s in experiment.species:\n",
    "            if s not in self.bounds.keys():\n",
    "                self.bounds[s] = [0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1fa0121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulation:\n",
    "    def __init__(self, species_range: Theoretical_Ranges, experiment: Experiment, max_digit = 4):\n",
    "        self.species_range = species_range\n",
    "        self.experiment = experiment\n",
    "        self.maxdigit = max_digit\n",
    "        self.species_range.check_compatibility(experiment=self.experiment)\n",
    "\n",
    "    def create_xml_files(self, output_xmls_path: str, num_of_xmls: int, xml_template_path: str) -> None:\n",
    "        if not os.path.exists(output_xmls_path):\n",
    "            os.makedirs(output_xmls_path)\n",
    "        self.num_of_xmls = num_of_xmls\n",
    "        env = jinja2.Environment(loader=jinja2.FileSystemLoader(os.path.dirname(xml_template_path)))\n",
    "        self.template = env.get_template(os.path.basename(xml_template_path))\n",
    "\n",
    "        for i in range(1, num_of_xmls+1):\n",
    "            self.random_ics = self.get_random_ics()\n",
    "            self.experiment.quantitated_exp_data(ics=self.random_ics)\n",
    "            self.make_xml_output(i, output_xmls_path)\n",
    "\n",
    "    def get_random_ics(self) -> dict[str, float]:\n",
    "        random_ics = {}\n",
    "        #random_ics = {s: np.random.uniform(*self.species_range.bounds[s]) for s in self.species_range.bounds}\n",
    "        for key in self.species_range.bounds:\n",
    "            if self.species_range.bounds[key][0] == 0 and self.species_range.bounds[key][1] == 0:\n",
    "                random_ics[key] = 1e-13\n",
    "            else:\n",
    "                random_ics[key] = np.random.uniform(*self.species_range.bounds[key])\n",
    "        for s in self.experiment.stresses:\n",
    "            random_ics[s] = self.experiment.stresses[s][0]\n",
    "        random_ics[\"REF\"] = 1.0\n",
    "        return random_ics\n",
    "\n",
    "    def make_xml_output(self, file_index: int, output_xmls_path: str) -> None:\n",
    "        dataPoints = [self.compileDataRow(row.values) for _, row in self.experiment.quant_data.iterrows()]\n",
    "        output = self.template.render(ics=self.random_ics, variables=self.experiment.species, dataPoints=dataPoints, bib=self.experiment.bibtex)\n",
    "        padded_number = str(file_index).zfill(self.maxdigit)\n",
    "        filename = f\"{self.experiment.bibtex['author'].split()[0][:-1]+'_'+self.experiment.bibtex['year']}_{self.experiment.name}_{padded_number}.xml\"\n",
    "        with open(os.path.join(output_xmls_path, filename), 'w') as f:\n",
    "            f.write(output)\n",
    "\n",
    "    def compileDataRow(self, dataPoints):\n",
    "        meas = \"\".join(f\"<{v}>{{:.4e}}</{v}>\" for v in self.experiment.experiment_data.columns)\n",
    "        return f\"<dataPoint>{meas.format(*dataPoints)}</dataPoint>\"\n",
    "    \n",
    "    def generate_opp_content(self, xml_folder: str, mech_file: str = \"7_Krisztian/mech/BCRN6.inp\", \n",
    "                            name: str = 'stac', yaml_file: str = \"7_Krisztian/mech/BCRN6.yaml\", time_limit: int = 50, thread_limit: int = 32,\n",
    "                            settings_tag: str = \"systems_biology\", solver: str = \"cantera\", extension: str = \".xml\") -> str:\n",
    "\n",
    "      # Create MECHMOD section\n",
    "      mechmod = f\"\"\"MECHMOD\n",
    "      USE_NAME         BCRN6\n",
    "      MECH_FILE        {mech_file}\n",
    "      COMPILE_cantera  {yaml_file}\n",
    "      END\n",
    "      \"\"\"\n",
    "\n",
    "      # Create MECHTEST section\n",
    "      mechtest = f\"\"\"MECHTEST\n",
    "      MECHANISM  BCRN6\n",
    "      TIME_LIMIT {time_limit}\n",
    "      THREAD_LIMIT {thread_limit}\n",
    "      SETTINGS_TAG {settings_tag}\n",
    "      FALLBACK_TO_DEFAULT_SETTINGS\n",
    "\n",
    "      SOLVER {solver}\n",
    "      SAVE_STATES      CSV\n",
    "      \"\"\"\n",
    "\n",
    "      # Add each XML file name\n",
    "      for xml_idx in range(1, self.num_of_xmls+1):\n",
    "          padded_number = str(xml_idx).zfill(self.maxdigit)\n",
    "          mechtest += f\"      NAME {xml_folder}/{name}_{padded_number}.xml\\n\"\n",
    "\n",
    "      mechtest += \"END\\n\"\n",
    "\n",
    "      return mechmod + \"\\n\" + mechtest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48bdaccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "alma = {'1': 'korte', '2': 'eper', '3': 'barack', '4': 'banan'}\n",
    "\n",
    "for a in range(1, 11):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa818e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_in_cells = 1e+12 * np.array([100, 50, 10, 5, 1, 0.5, 0.1, 0]) / 300000\n",
    "stresses: dict[str, NDArray[np.float_]] = {'rap': rap_in_cells}\n",
    "rap_in_cells.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c177f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Theoretical_Ranges.__init__() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m input_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRAP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCCH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREF\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInsulin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTG_SERCA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmTOR_RAP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIP3R\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaxa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtBid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m must_be_zero \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBaxa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtBid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp53a\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPUMA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m rng \u001b[38;5;241m=\u001b[39m \u001b[43mTheoretical_Ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_files/reactions_ics_finalised.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43micranges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                               \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmust_be_zero\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m rap_in_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-12\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m200000\u001b[39m\n\u001b[1;32m      7\u001b[0m stresses \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrap\u001b[39m\u001b[38;5;124m'\u001b[39m: rap_in_cells}\n",
      "\u001b[0;31mTypeError\u001b[0m: Theoretical_Ranges.__init__() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "input_names = ['nS', 'RAP', 'TG', 'dS', 'CCH', 'REF', 'Insulin', 'TG_SERCA', 'mTOR_RAP', 'casp', 'IP3R', 'Baxa', 'tBid']\n",
    "must_be_zero = ['casp', 'Baxa', 'tBid', 'p53a', 'PUMA']\n",
    "\n",
    "rng = Theoretical_Ranges('input_files/reactions_ics_finalised.xlsx', 'icranges',\n",
    "                               input_names, must_be_zero)\n",
    "rap_in_cells = 1e-12 * np.array([100, 50, 10, 5, 1, 0.5, 0.1, 0]) / 200000\n",
    "stresses: dict[str, NDArray[np.float_]] = {'rap': rap_in_cells}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_xlsx_path = self.exp_file_btn.text()\n",
    "range_csv = self.range_file_btn.text()\n",
    "xml_template = self.template_file_btn.text()\n",
    "output_dir = self.output_dir_btn.text()\n",
    "opp_output_dir = self.opp_output_dir_btn.text()\n",
    "num_xml = self.num_xml_input.value()\n",
    "scaling_factor = float(self.scaling_input.text())\n",
    "first_species_col = self.first_col_input.value\n",
    "# Parse stresses\n",
    "stress_parts = self.exp_info_input.text().split()\n",
    "if len(stress_parts) == 3:\n",
    "    stresses = {stress_parts[0]: (stress_parts[1], float(stress_parts[2]))}\n",
    "elif stress_parts[0] != \"molecular_species\":\n",
    "    stresses = {stress_parts[0]: (\"\", \"\"\n",
    "# Read all sheets from Excel\n",
    "all_sheets = pd.read_excel(exp_xlsx_path, sheet_name=None)  # dict of {sheet_name: DataFram\n",
    "# Extract BibTeX from the last sheet\n",
    "last_sheet_name = list(all_sheets.keys())[-1]\n",
    "bibtex_df = all_sheets[last_sheet_name]\n",
    "# Ha nem lenne header a BibTex-nel, akk ezzel kell beolvasni a sheetet: bibtex_df = pd.read_excel(exp_xlsx_path, sheet_name=last_sheet_name, header=Non\n",
    "# Join all non-empty strings from the first column into a BibTeX string\n",
    "bibtex_lines = bibtex_df.iloc[:, 0].dropna().astype(str).tolist()\n",
    "bibtex_str = \"\\n\".join(bibtex_line\n",
    "print(\"\\n\", bibtex_str, \"\\n\n",
    "if len(bibtex_str) == 0:\n",
    "    QMessageBox.warning(self, \"Input Error\", \"No valid BibTeX found in the last worksheet.\")\n",
    "    return\n",
    "\n",
    "date = datetime.datetime.now\n",
    "for sheet_name in list(all_sheets.keys())[:-1]:\n",
    "    df = all_sheets[sheet_name]\n",
    "    exp = Experiment(df, stresses, bibtex_str)\n",
    "    exp.name = sheet_name\n",
    "    rng = TheoreticalRanges(range_csv, scaling_factor, first_species_col)\n",
    "    sim = Simulation(rng, exp)\n",
    "    sim.create_xml_files(output_dir, num_xml, xml_template)\n",
    "    opp_content = self.generate_opp_content(output_dir, sheet_name)  # Create .opp file content\n",
    "    opp_filename = f\"{date.year}{date.month}{date.day}_BCRN_{exp.bibtex['author'].split()[0][:-1]}_{sheet_name}.opp\" # Define output .opp file path\n",
    "    with open(os.path.join(opp_output_dir, opp_filename), \"w\") as f:\n",
    "        f.write(opp_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
